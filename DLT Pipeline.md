- Delta Live Table의 준말
- Databricks에서 신뢰할 수 있고 유지 관리가 용이하며 테스트 가능한 파이프라인을 쉽게 구축, 관리할 수 있는 프레임 워크
- DLT는 **선언적 파이프라인 개발 방식**을 제공함
	- 사용자가 sql, python으로 정의만 하면
	- DLT가 데이터 종속성, 인프라 관리, 작업 Orchestration, 오류 처리, 성능 최적화 등 많은 운영 복잡성 자동 처리

## 주요 특징
- 선언적 개발
	- 데이터 변환의 최종 상태 선언시, DLT가 실행 계획 처리
	- SQL, Python 지원
	- 각 노트북이나 파일에는 하나의 언어만 사용 가능
		- 단, pipeline에서 혼합하여 사용 가능
- 자동화된 ETL 개발 간소화
	- 인프라 관리, 작업 Orchestration, 데이터 종속성 추적, 오류 처리 및 복구, 성능 최적화 자동화
	- DE가 고품질 데이터에만 집중하도록 지원
- 증분 및 스트리밍 처리
	- 배치 처리, 스트리밍 처리 모두 지원
	- 데이터의 증분 처리에 효율적
	- 스트리밍 테이블은 입력 테이블을 exactly-once로 처리
	- CDC(변경 데이터 캡처) 지원
- 데이터 품질 관리 및 모니터링
	- expectations를 정의하여 파이프라인을 통해 이동하는 데이터의 유효성 검사
		- 규칙 위반시 데이터 삭제, 실패, 별도 테이블 적재 가능
	- 이벤트 로그를 통해 pipeline metric, audit logging, data lineage 등 확인 가능
- Delta Lake 기반
	- DLT에서 생성, 관리되는 테이블은 Delta Lake 테이블
	- ACID Transaction, Time traveling등의 Delta Lake의 모든 기능 사용 가능
- 자동 확장 및 최적화
	- workload 볼륨에 따라 클러스터 리소스를 자동으로 할당
	- 클러스터 사용률을 최적화, 데이터 처리 대기 시간에 미치는 영향 최소화
- 개발 및 운영 효율성
	- 개발모드 지원
	- 대화형 개발 및 테스트 용이
	- 노트북 내에서 DLT 그래프, 이벤트 로그 확인하여 개발 가능

## DLT Pipeline 구성 요소
- 소스 코드
	- SQL, Python으로 작성된 노트북이나 작업 영역 파일
	- 데이터 세트, 변환 로직 정의
- 파이프라인 설정
	- 파이프라인 인프라, 종속성 관리, 업데이트 처리 방법, 테이블 저장 위치 제어
- 대상(Target)
	- 파이프라인 결과 데이터가 저장될 위치나 스키마 지정
- 노트북 라이브러리
	- 파이프라인에 사용될 코드(노트북)의 경로 지정