---
date: 2024-12-22
datetime: 2024-12-22 16:46:23
book: 데이터_거버넌스
page:
  - "33"
tags: 
references: 
aliases:
---
- [[데이터 거버넌스]]란

# 데이터 거버넌스는 무엇에 관여하는가
- 클라우드의 이동, 컴퓨터 성능 향상 -> 빅데이터 분석이 가능해짐
	- 인사이트, 의사결정을 위한 데이터 수집, 저장, 분석하려는 데이터 소비자 공동체 빠르게 성장
- 새로운 데이터 집합 수집에도 관여
- 데이터 수집과 빅데ㅌ이터 분석이 가진 가능성만 보고 싶겠지만,
	- 데이터 거버넌스는 무시해서는 안되는 중요한 고려사항
- 잘 주관된(well-governed)는 데이터 조직에 이득을 가지고 올 수 있음

### 스포티파이의 새 위클리 추천곡 서비스
- data governance에 따라 성장하게 된 시장
- 당시 음악 불법 복제가 음악 산업을 훼손하던 상황에서
	- 음반사들이 작업의 대가를 받는 한 방법으로 출발함
- 사용자에게 노래를 추천할 때, 한곡씩이 아닌
	- 추천곡의 재생목록을 spotify에서 만들어서 제안
	- 매주 월요일에 제시

## 데이터 거버넌스에 대한 [[전일적 접근방식]]
- 개인 식별 정보(Personally Identifying Information, PII)를 포기한 데이터 수집 방식
	- 익명 정보를 통해 신뢰성이 다소 낮더라도 활용한 사례
	- 새로운 데이터 집합으로 기존 데이터 집합 보정, 데이터 품질 향상
- 데이터 거버넌스의 렌즈를 통해 연구팀은
	- 어떤 보고서 데이터를 수집할지 신중히 고려
	- 기업 데이터의 품질 개선
	- 미국 국립 기상청 생성 예보 품질 향상
	- 전반적인 브랜드 기여 향상
- 데이터 거버넌스에 대한 [[전일적 접근방식]](holistic approach)의 결과
- 오늘날 데이터의 분류, 검색, 가용성, 접근성, 무결성, 보안을 관리하는데 어떤 best practice를 적용하고 정책을 마련할 것인가
	- 즉, 데이터 거버넌스를 어떻게 수행할 것인가
- 기업이 데이터 거버넌스를 수행하기 위해 사용할 수 있는 도구와 역량은 강력하고 다양함
	- 처음에는 법률, 규제 준수의 관점뿐 아니라
	- 거버넌스 정책 활용시 성장 촉진 및 비용 감소도 가능함

## 데이터의 신뢰 향상
- 데이터 거버넌스의 궁극적인 목적: 데이터에 대한 신뢰 구축
- 데이터에 대한 이해관계자의 신뢰를 높일 수 있을 때,
	- 구체적으로는 데이터의 수집, 분석 발행, 사용을 이해 관계자가 좀 더 신뢰할 수 있을 때 가치가 있음
- **데이터 신뢰를 확보하기 위한 데이터 거버넌스 전략**
	- 발견성(discoverability)
		- 발견성 자체를 위해서는 데이터 거버넌스가
			- 기술 메타데이터, 계보 정보(lineage information), 비즈니스 용어집(business glossary)을
				- 사용자가 언제라도 사용할 수 있도록 준비해야 함
			- [[비즈니스 크리티컬 데이터]]는 완전해야 함
		- 데이터가 세밀하게 분류되었는지 확인하는,
			- 실수 혹은 악의적인 변경 및 외부 유출(exfiltration)로부터 데이터를 적절히 보호하기 위한 기준 정보 관리(master data management)도 필요함
	- 보안(security)
		- 비즈니스 분야와 데이터 집합의 특성에 따라
		- 규제 준수, 민감한 데이터(e.g. 개인 식별 정보) 관리, 데이터 유출 방지 등이 모두 중요한 사안
	- 설명책임성(accountability, 책무성)
		- 데이터 도메인들의 경계선에 관한 소유권, 설명 책임성에 대한 운영 모델 제공 필요
- 발견성 + 보안 보장시 데이터 자체를 하나의 **상품**으로 취급 가능
	- 이 시점에 설명 책임성이 중요해짐

## 분류 및 접근 제어
- 데이터 거버넌스의 목적, 사업상의 이점을 위해 기업 데이터의 신뢰도를 높히는 것이긴 하나
	- 주요 활동은 여전히 classification(분류)와 access cotrol(접근 제어)와 관련이 있음
	- 주요 역할을 이해하기 위해 위 활동들의 설정을 고려하는 것이 도움이 됨
- 예시: HR 정보를 보호하는 문제
	- 인적 자원, 여러가지 데이터 요소 포함
	- 각 직원의 이름, 고용 일자, 임금 지급 내역, 은행 계좌, 현재 임금 등
	- 각 요소들은 **분류 수준**에 따라 다른 방식으로 보호됨
		- public: 기업 무관한 사람도 접근 가능
		- external: 협력사, 하청업체가 기업의 허락하에 내부 시스템 접근
		- internal: 조직의 모든 임직원 접근
		- restricted: 인가된 임직원만 가능
	- 위 제한이 더 동적일 수도 있음
		- 직원의 현재 임금은 관리자만 볼 수 있고
		- 각 관리자는 자신의 보고서에 필요한 임금 정보만 확인 가능
	- 접근 제어 정책은 사용자가 데이터에 액세스할 때 수행할 수 있는 작업을 규정
		- 새 레코드 생성, 기존 레코드를 읽기/갱신/삭제
- 역할별 구분
	- **[[데이터 주관자]]**
	- 정책 자체의 구현은 데이터베이스 시스템이나 응용 프로그램을 운영하는 팀이 맡을 수 있음
	- [[데이터 스튜어드]]
	-  **[[데이터 사용자]]**
	-  **[[지식 노동자]]**
- 어떤 기업은 개방(open)을 기본 정책으로 둠
	- 비즈니스 데이터의 경우 기업의 모든 지식 노동자 = 인가된 사용자 영역에 속함
- 어떤 기업은 폐쇄(closed)를 기본 정책으로 둠
	- 꼭 필요한 사람만 비즈니스 데이터에 접근하도록
- 어떤 정책을 사용할지는 데이터 거버넌스 위원회가 결정할 일
	- 어떤 접근 방식이 최선인지에 대한 보편적 정답은 없음

## 데이터 거버넌스 대 데이터 활성화 및 데이터 보안

### [[데이터 거버넌스]]

### [[데이터 활성화]]

### [[데이터 보안]]

# 데이터 거버넌스가 점점 더 중요해지는 이유
- 데이터 거버넌스는 주관할 데이터가 생겼을 때부터 존재함
- legacy 데이터 처리 시스템에도 데이터 품질을 보장할 뿐만 아니라
	- 데이터에 대한 접근 제어 방법이 필요함
- 전통적으로 데이터 거버넌스는
	- data source의 유형과 연관된 silo 안에서 수행되는 하나의 IT 기능으로 간주됨
- 대부분의 회사는 데이터 거버넌스를 하나의 부서별 관심사(departmental cencern)로 간주
- 근래에 데이터 거버넌스가 중요해진 이유
	- GDPR, CCPA 같은 규제
		- 보건과 금융을 포함한 몇몇 규제 대상 업계가 아닌 모든 산업에 영향
	- 데이터의 비즈니스 가치에 대한 인식이 높아짐
- 시간이 흐르고 데이터 지형이 바뀌면서
	- 데이터 거버넌스에 대한 접근 방식과 수행 방법도 변화함

## 데이터의 크기가 증가하고 있다
- 기술 발달로 데이터 수집량 증가
	- 예측 분석 능력이 향상된 덕분

## 데이터를 다루거나 열람하는 사람의 수가 기하급수적으로 증가
- 데이터 주도적 의사결정에는 많은 인력이 필요
	- 이를 위해 데이터 파이프라인을 설정하는 기술자
	- 대시보드와 보고서를 보는 이해관계자
- 데이터를 다루고 열람하는 사람이 많을 수록 데이터의 오용 가능성이 커짐
	- 데이터의 접근, 사용을 관리하는 복잡한 시스템의 필요성도 커짐

## 데이터 수집 방법의 발전
- batch 처리 뿐 아니라
	- 개인화된 참여를 제공하는데 실시간 스트리밍, 혹은 가까운 스트리밍 서비스 제공
- 스트리밍의 출현으로 분석 속도가 크게 빨라지면서
	- 침입의 잠재적 위험 역시 증가
	- 보호를 위한 복잡한 설정, 모니터링 필요

### 스포츠 분야의 발전된 데이터 수집
- 예전 스포츠 통계: 승리 횟수, 패배 횟수와 같은 단순 통계
- 요즘은 스포츠 수집 데이터 양과 종류가 증가함
- 미국내 NFL(National Football League)에서 2015년부터 리그 전체에 분석을 사용함
- Big Data Bowl이라는 스포츠 분석 경진대회도 개최함

## 수집되는 데이터의 종류가 늘어나고 있다(좀 더 민감한 데이터도 포함해서)
- 2025년, 모든 사람의 하루 디지털 데이터 참여(digital data engagement)가
	- 1인당 4900건 이상이라고 예측
	- 약 18초마다 한 건의 데이터 상호작용을 의미
- 이런 상호작용의 대부분에서 아주 다양한 **민감한 데이터**가 생성되고 수집됨
	- 신용카드번호, 주민등록번호, 이름, 주소, 건강 상태등
- 극도로 민감한 종류의 데이터 수집이 성행하면서
	- 데이터의 사용, 처리, 열람 권한에 대한 고객(규제 당국)의 우려가 커짐

## 데이터의 용례 확장
- [[데이터 주도적 의사결정]]
- 회사들은 내부적으로 일상 업무 수행에 데이터를 활용하는 것에 머무르지 않고,
	- 고객이 더 나은 결정을 내리도록 돕는데에도 데이터 활용
- 대표적인 예시는 아마존
	- 아래 5가지의 항목을 분석해서 맞춤형 메세지, 추천 상품 제시하는데 활용
		- 고객이 구매한 상품, 조회한 상품, 가상 쇼핑카트에 담은 상품
		- 구매 후 평점, 상품평을 쓴 상품
- 아마존의 용례가 비즈니스 면에서는 합리적이나
	- 그런식으로 활용하는데에는 적합하지 않거나 불법인(민감한) 데이터가 존재함을 주의해야 함
- 민감한 종류의 데이터는 데이터의 취급 방식 뿐 아니라 사용 방식도 중요함
	- 직원 데이터를 회사의 인사 부서에서 내부적으로 사용, 열람 하는 것은 괜찮으나
	- 마케팅 부서에서 사용/열람 하는 것은 부적절

### 더 나은 의사결정을 위한 데이터 활용
- 온라인에서 무언가를 검색할 때 추천 항목이 어떻게 표시되는가

#### Safari Books Online
- 현대적인 분석 도구 활용하여 매출 증가
- 방대한 양의 사용 데이터, 사용자 검색 결과, 추세로부터 가치 발굴
- 그 모든 데이터를 연결해서 sales intelligence를 개선, 매출 증대
- 위와 같은 목적을 실시간으로 달성할 수 있는가
	- 실시간 통찰을 위해 CDN(Content delivery Network)에 대응되는 사용량 데이터를 cloud-native DW로 정기적으로 전송
	- 원래의 사일로 외부에서도 정보 활용하도록 구성
	- ![[Drawing 2025-01-30 18.15.34.excalidraw]]
- Safari books online 팀은 데이터를 심층 분석,
	- 다양한 대시보드와 더 나은 사용자 환경 제공
	- ad-hoc query(임시 질의)도 빠르게 처리하고자 함
- 새로운 분석 덕분에 사용자 지원이 빠르고 간편하며, 고객 만족도가 높아짐
	- 팀이 사용자 주요 정보(IP, 검색한 책 제목)을 거의 실시간으로 얻을 수 있기 때문
- Safari books online이 [[데이터 주도적 의사결정]]을 시작할 때 가장 중요하게 생각한 용례
	- 더 나은 영업 정보를 확보하는 것
		- 예전의 웹 로그에 묻혀 있었거나 아예 사용불가한 모든 데이터를 영업을 위한 단서로 전환
	- 잠재적 독자의 관심도에 대한 평가를 CRM에 통합
		- 실행 가능한 정보로 신속하게 전환

#### California Design Den
- 가격 책정 및 재고 관리 데이터로 의사 결정 프로세스 혁신을 이룸
- 스마트 분석 플랫폼을 활용하여 가격 결정, 재고판매가 빨라지고 수익 증대
- 핵심: 의사결정을 위해 다양한 유형의 데이터를 aggregation 하는 능력
	- 보존해야 할 데이터와 제거해야 할 데이터의 균형을 맞추는 능력 포함

#### 데이터 주도적 의사결정의 과정
- **모든 데이터가 더 나은 의사결정에 가치있는 것은 아님**
- [[데이터 주도적 의사결정]] 과정 확립시 편견을 경계하는 것도 중요
- 목표를 잘 정의해야 하며(처음에는 측정하기 쉬운 목표치 몇가지 설정), 답을 얻고자 하는 고가치 질문(high-value question)을 정해야 함
	- 필요하다면 다시 돌아가서 출발점, 목표, 척도를 재고찰해도 좋음
		- 답은 데이터에서 찾아야 하나, 다양한 관점에서 데이터를 바라보면
		- 답에 중요한 데이터가 무엇인지 파악하는데 도움이 됨
- [[데이터 주도적 의사결정]]에서 value chain의 핵심 부분은 고가치 질문들을 던져서 좀 더 심층적인 통찰을 얻는 것
	- 목적이 영업 정보를 활용하여 매출 정보를 늘리거나
	- 고객 지원, 경험을 개선하거나
	- 악의적인 사용을 감지하여 운영 문제를 방지하거나
	- [[데이터 주도적 의사결정]]은 모든 비즈니스와 운영의 핵심
		- 시중에는 귀중한 데이터의 활용을 돕는 다양한 스마트 도구들 존재
## 데이터 취급에 관한 새로운 규제와 법규
- 데이터 양, 가용량의 증가 => 데이터 자체와 데이터의 수집, 접근, 사용을 규제하려는 요구와 필요성
- 오래전에 생긴 규제
	- HIPAA(Health Insurance Portability and Accountability Act): 건강 보험 이식성 및 책임법
		- 개인 의료 데이터의 수집과 사용을 보호하는 법안, 1996년에 제정
		- 위와 같은 규정은 잘 알려져 있으며, 대상 사업체들이 수십년 동안 준수
			- 민감한 데이터 처리하는 과정, 방법은 정교함
	- GDPR(General Data Protection Regulation): 일반 데이터 보호 규정, EU
- CCPA(California Consumer Privacy Act): 캘리포니아 소비자 개인정보보호법, 미국
	- 새로운 규제
- 위와 같은 규제들은 수많은 회사에 적용되는 데이터 사용, 수집 규제의 두 가지 예일뿐임
- 아직 데이터의 거버넌스를 아직 자신의 데이터 아키텍처 전략에 포함하지 않은 회사도 많음
	- 그래서 예전에는 규제 준수를 고려하지 않던 회사들이 규제를 준수하기 위해
	- 자신의 기술, 업무 프로세스를 수정하는데 어려움을 겪음

## 데이터 사용에 관한 윤리적 우려 사항
- 데이터의 용례 자체도 윤리적 사용이라는 범주에 넣을 수 있으나
	- 요즘은 ML, AI의 신기술이 데이터의 윤리적 사용에 관한 새로운 걱정거리 제공
- 자율주행차에 의한 사고, 히츠버그 사례
	- 책임을 누가질 것인가?
- 위와 같은 사고들은 회사의 홍보 부서에는 엄청난 악몽
- EU 규제 당국은 [[AI 시스템을 신뢰할 수 있다고 간주하려면 충족해야 하는 7대 요건]]을 발표함
- 더 많은 데이터와 안정적인 분석에 힘입어 [[데이터 주도적 의사결정]]을 하려면
	- 위 규제 요건들이 요구하는 것보다 더 집중해서 고려할 필요가 있음

## 데이터 거버넌스의 실제 적용 사례
- 데이터 거버넌스가
	- 접근성과 보안 관리에 쓰이고 있다는 점
	- 데이터 품질을 정면으로 다루어서 신뢰 문제를 해결
	- 거버넌스 구조가 이러한 노력을 성공으로 이끈다는 점

### 발견성, 보안, 설명책임성의 관리
- Capital One: 2019.07, 세계 최대의 소비자 및 중소기업 신용카드 발생사
- 외부인이 Apache Web server의 설정 오류를 악용하여 웹 앱 방화벽을 침해한 사실 발견
- 공격자는 임시 자격증명 획득
	- Capital One 고객의 개인정보가 담긴 파일에 접근 가능
	- 이런식으로 유출된 정보는 Capital One 신용 카드를 신청한 1억 명 이상의 개인에게 영향을 미침
- 이 유출사고의 피해가 더 커지지 못하게 제한한 요인 두가지
	- 유출된 정보는 캐피털 원으로 전송된 신용카드 신청 데이터
		- 이름, 주민번호, 은행 계좌 번호, 주소는 있었으나
		- 공격자가 돈을 훔치는 데 사용할 로그인 자격증명은 없었음
	- 공격자를 FBI가 신속하게 검거
- 문제의 파일들은 어떤 public cloud 저장소의 bucket에 있었음
	- 그 클라우드 저장소는 버킷에 대한 모든 접근을 로그로 남김
	- 그 덕분에 사건 발생 이후 조사관들이 IP 접근 경로 파악, 발원지를 주택 n채로 좁힘
- IT 시스템의 설정 오류로 보안 취약점이 발생하는 것은 어디서나 일어나나,
	- 일반적으로 on-premise 시스템에서 관리자의 자격증명을 훔친 공격자는
		- 시스템 접근 로그를 수정해서 자신의 흔적을 감춤
	- 반면에 public cloud는 공격자가 공용 클라우드 자체를 뚫지 않는 한 그런 로그 수정 불가
- 이 사건에서 배울 몇 가지
	- 데이터 수집은 그 목적이 명확해야 함
		- 또한 데이터를 가능한 한 좁은 범위의 조각들로 나누어 저장하는 것이 좋음
	- [[data_warehouse|데이터 웨어하우스]]에 조직 수준 감사 로그를 활성화 해야함
		- 공격자의 빠른 검거를 도움
	- 모든 열린 포트에 주기적으로 보안 감사 수행 필요
		- 보안 보호 장치를 우회하려는 시도가 있을 때 경고를 받기 위함
	- 문서 안의 민감한 데이터에 대해 추가적인 보안 계층을 적용해야 함
		- [[SSN]]은 [[PII]] 데이터를 식별하고 삭제할 수 있는 인공지능 서비스 활용 하여 마스킹 하거나 토큰화 필요
- 위 4가지 모범관행은 추가적인 안전장치
	- 꼭 필요한 데이터만 수집하고 저장한다면 마스킹은 필요하지 않을 수 있음
- 데이터를 여러 용도로 활용하는 것을 효과적으로 하려면
	- 데이터 요소의 각 속성에 다중 범주에 기반한 태그 or 레이블을 지정하여 적절한 제어 및 보안 적용 필요
- 이를 위해 사업체 내 여러 조직의 협력이 필요함
- 그리고 이처럼 특정 데이터를 고려 대상에서 제거하는 시스템에는
	- 그 나름의 난제와 위험이 따른다는 점도 염두해야 함
- 기업이 수집하고 보유하는 데이터가 증가함에 따라
	- 위와 같은 모범 관행을 잘 이해하고 올바르게 구현 필요
	- 모범관행과 정책, 그리고 그를 구현하는 도구는 데이터 거버넌스의 필수 요소
### 데이터 품질 개선
- 데이터가 조직에 유용하려면 데이터를 신뢰할 수 있어야 함
	- 데이터 품질이 중요
- 데이터 거버넌스에서 대부분의 초점
	- downstream 프로그램이 데이터의 무결성을 신뢰할 수 있게 만드는 것
- 데이터를 조직이 소유하지 않을 때,
	- 데이터가 한 곳에서 다른 곳으로 이동할 때 이를 보장하기가 어려움
- 데이터 거버넌스의 활동으로 데이터 품질을 개선한 좋은 예시
	- USCG(US Coast Guard, 미국 해안 경비대)의 사례
- 데이터가 깨끗하면 깨끗할 수록 좀 더 중요한 용량에 사용량 가능성이 높아짐

#### USCG, 미국 해안경비대가 데이터 품질을 개선한 방법
- 해상 수색 및 구조, 해양 유출 정화, 해양 안전 및 법 집행에 중심을 둔 조직
- AVIS(Authoritative Vessel Identification Service)로 통용되는 시스템에 쓰인 데이터 거버넌스의 개념과 기법
- 데이터의 불일치가 발생함에 따라 USCG는 특정 선박의 위치 및 기타 정보를 현장에서 파악하기 어려웠음
	- 자동화된 도구가 아닌 사람의 개입이 필요한 선박
- 거의 대부분의 경우 문제는 사소한 실수 때문이었지만 바로잡으려면 문제점을 파악하고 관련 해양 공동체에 도움을 청해야 했음
- AVIS가 도움이 된 몇 가지 정성적(qualitative) 사례
	- 어떤 선박이 뭔가를 위반해서 조사를 받거나, 특정 이유로 운항이 금지되었을 경우
	- 그 선박이 동일한 MMSI 번호를 전송하는 여러 선박 중 하나일 경우, 선박의 추적 정보가 중복된 식별 번호로 파악됨
	- USCG의 구조선보다 더 빨리 도움을 줄 수 있는 인근 선박을 찾아야 하는 수색, 구조 상황일 경우
		- 위 결함은 더욱 심각한 문제가 될 수 있음
- 시간이 지남에 따라 파일럿 프로그램에 보고되는 모호한 선박 트랙 수가 급격히 감소
	- 공동체의 노력으로 이루어지는 일
	- 지속적인 유지보수 및 관리
