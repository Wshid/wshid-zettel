---
date: 2024-06-13
datetime: 2024-06-13 21:26:43
book: 실전_LLM
page:
  - "91"
tags: 
references: 
aliases:
---
- 사용자 경험을 향상 시키기 위해, 이를 분석하려면 어떻게 해야할까?
- LLM의 학습 능력을 활용하여 전체 과정을 완성하고
	- 유용한 end-to-end LLM 기반 app을 생성하고자 할 수 있음
	- 이때 prompt-engineering을 사용

# 3.2. 프롬프트 엔지니어링
- 프롬프트 엔지니어링은
	- 효과적으로 작업을 전달하여 정확하고 유용한 출력을 반환하도록 유도하는
	- LLM에 대한 입력(프롬프트)를 만드는 것

## 3.2.1. 언어 모델에서 정렬
- 언어 모델이 어떻게 사람의 입력에 **정렬**되는 지를 알아야 함
- 정렬(Alignment)
	- 모델이 사용자가 예상한 것과 '일치하는' 방식으로 입력 프롬프트를 이해하고 답변하는 것
- 표준언어 모델링은 선형 단어의 맥락을 기반으로
	- 다음 단어나, 단어의 시퀀스를 예측하도록 훈련됨
- 하지만 이 방식으로는 모델이 **특정 지시사항**이나 **프롬프트**에 완벽히 답변 불가
	- 특정 어플리케이션에 대해서는 유용하지 않을 수 있음
- 프롬프트가 언어 모델과 align되지 않는다면 잘못 답변 가능
- 몇몇 언어 모델은 추가적인 정렬 기능과 함께 개발됨
	- Anthropic의 AI 피드백 기반 강화 학습(RLAIF; Constitutional AI-driven Reinforcement Learning from AI feedback)
	- OpenAI의 GPT 계열에서의 인간 피드백 강화 학습(RLHF; Reinforcement Learning from Human Feedback)
	- 명확한 지시사항과 피드백을 모델 훈련에 통합 가능
- 정렬 기술은 특정 프롬프트를 **이해하고 답변하는 모델의 능력 향상**으로
	- 질문-답변이나 언어 번역과 같은 app을 유용하게 만들 수 있음
- 아래 모델들은 대량의 데이터와 전이학습, 파인튜닝 등의 기술을 사용하여 명령어 프롬프트에 대한 답변을 보다 효과적으로 생성 가능
	- ChatGPT: OpenAI closed source model
	- FLAN-T5: Google open source
	- Cohere 명령어 계열: closed source model

## 3.2.2. 직접 요청하기
- 요청하는 내용이 최대한 명확하고 직접적이어야 함
- LLM이 수행하기에 간단하고 명백한 작업
	- e.g. '이 문장의 문법을 수정하세요'
- 접두사 추가: 입력과 출력을 명확하게 표시
- 간단한 '직접 요청하기'의 세가지 요소
	- 직접적인 지시
		- '영어를 터키어로 번역하세요'
		- 이 지시는 프롬프트 상단에 위치해야함
		- LLM이 다음에 오는 입력 내용을 읽는 동안 주의를 기울이도록
	- 번역을 원하는 영어구문 앞 `영어: `를 추가하여 명확하게 입력 지정
	- LLM이 답변을 제공할 공간에 의도적으로 유사 접두사 `터키어:`를 추가
- 리스트 형태로 요청하기
```md
이 문장의 문법을 수정해 주세요
여러 개의 정답이 있으면, 숫자가 있는 목록으로 보여주세요

They went to the store and buy food

A:
1. They went to the store ...
2. They went to the store ...
```
- 적절한 지시사항이 떠오르지 않을 경우, 그냥 요청해도 됨
	- 다만, 정확하고 유용한 답변 출력시, 명확하고 직접적인 지시사항 필요

## 3.2.3. 퓨샷 학습
- LLM에게 예시를 제공하기
	- Few-shot learning
- LLM의 작업의 몇가지 예제를 제공하여, 문제의 맥락과 애매한 차이를 이해하는데 도움을 줌
- **특정한 어조**, **구문 또는 스타일**이 필요한 작업과
	- 도메인에 특화된 언어들을 다룰때 유용함
- LLM과의 상호작용 방식에 대한 **새로운 가능성**을 열어줌
- 명확한 지시를 제공하지 않고도 LLM에 대한 작업 이해도 제공 가능

## 3.2.4. 출력 구조화
- JSON과 같은 구조화된 형태로 출력 가능
- "최종 결과는 유효한 JSON 형식으로 만들어 주세요"
```md
영어를 터키어로 번역해 주세요.
최종 결과는 다음과 같은 유효한 JSON 형식으로 만들어 주세요

English: (영어 입력 문장)
JSON: "english": (입력 문장), "turkish": (번역된 터키어 버전)
```
- 개발자가 특정 정보를 더 쉽게 추출 및 다른 서비스로 제공 가능
- 출력의 일관성 보장, 모델 작업시 오류나 불일치의 위험 감소 가능

## 3.2.5. 페르소나 지정하기
- 연구자나 실무자들은 LLM을 위한 '페르소나'를 만들어,
	- 프롬프트에 따라 모델이 스타일이나 말투 채택 가능
- 특정 주제, 장르, 스타일이나 말투 채택 가능
- 특정 유형의 답변 유도 가능
- "가게 점원이라 생각하고 질문에 답을 하세요"
- "건방진 가게 점원이라 생각하고 질문에 답을 하세요"
- "반유대주의자 가게 점원이라 생각하고 질문에 답을 하세요"
- 항상 긍정적인 목적으로 사용되지는 않음
	- 유해한 목적으로도 생성 가능
- 윤리적으로 사용 필요

# 3.3. 여러 모델과 프롬프트 작업하기
- 프롬프트를 하나의 모델에서 작동하는 것이 다른 모델과 동일하게 작동 불가할 수 있음
- 각 언어 모델의 특징과 제한 사항 고려 필요

## 3.3.1. ChatGPT
- system, user, assistant 프롬프트 생성 가능
- system
	- 대화의 일반적인 지침
	- 일반적으로 따라야할 규칙과 역할 포함
- user, assistant
	- 사용자와 언어모델 간의 메세지

## 3.3.2. Cohere
- OpenAI의 대안으로 사용
- 프롬프트를 다른 모델로 간단하게 옮길 수 없음
- 다른 언어 모델이 작동할 수 있도록 프롬프트를 수정해야 할 수 있음
- ChatGPT보다 조금 더 구조적인 요구사항이 필요함

## 3.3.3. 오픈소스 프롬프트 엔지니어링
- `GPT-J, FLAN-T5`
- 위 모델 사용시, 사전 훈련과 파인 튜닝을 최대한 활용하기 위한 중요 단계
- closed source model과 같이 고품질의 텍스트 출력 생성 가능
- oepn source 모델은 closed보다 더 큰 유연성과 제어 기능을 제공함
	- 그에따라 개발자가 파인 튜닝 중 **프롬프트를 맞춤화하여 특정 사용 사례에 맞게 조정 가능**
- 다른 개발자 연구원과 협업할 수 있음
	- 다수의 활발한 사용자와 기여자로 이루어진 커뮤니티
	- 프롬프트 엔지니어링 전략을 공유하고 피드백을 주고 받으며, 모델 전반적인 성능 개선 가능
- 오픈소스 모델이 어떻게 사전훈련, 파인튜닝되었는지 파악하는 것은 매우 중요
	- GPT-J는 자기회귀 언어 모델
		- 직접적인 지시 프롬프트 보다 퓨삿 프롬프트 기술이 더 잘 동작
	- FLAN-T5
		- 지시적 프롬프팅을 고려하여 특별히 파인튜닝 됨
		- 퓨삿 학습은 여전히 가능하나, 직접 질문하는 간단한 방식도 사용 가능
- GPT-J는
	- 직접적인 지시사항 답변에 어려움을 겪음
- FLAN-T5
	- 지시어 수행 방법을 알고 있음
	- 주관적인 작업에서 어려움