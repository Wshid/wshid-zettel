
### 2.1. 들어가는 글

의미 기반 검색(Semantic Search) 분야
LLM을 기반으로 한 [[텍스트 임베딩]]을 생성하는 기능

텍스트 -> 벡터로의 대응은 일종의 **hash**로 생각할 수 있음
- 벡터 -> 텍스트는 불가능하나
- 인코딩된 상태에서 점수 비교가 가능한 **추가적인 이점** 확보가 가능
언어와 문맥의 이해를 통해 문장이나 단어 내포 의미 포착
- 언어 작업에 있어서 정확한 모델 개발 가능


### 2.2. 작업
- 검색엔진에 입력하는 단어는, 항상 예상하는 검색 결과에 사용된 단어와 정확하게 일치하지 않을 수 있음
- 동일한 단어가 검색한 것과 다른 의미를 가질 수도 있음

#### 2.2.1. 비대칭적 의미 기반 검색
- [[의미 기반 검색 시스템]]
- 비대칭(asymmetric)이란 불균형이 있는 것
	- 입력 쿼리의 의미 정보(기본적으로 크기)
	- 검색 시스템이 검색해야하는 문서/정보
- 기본적으로 둘중 하나는 짧음
	- e.g. 네 단어 정도의 쿼리는, 결과로 나오는 문단보다 짧음
-  쿼리에 정확한 단어를 사용하지 않더라도, 정확한 검색 결과를 얻는 것이 목표

### 2.3. 솔루션 개요

#### 단계
- 1단계, 문서 저장
	- 임베딩을 위한 문서 저장(항목의 단락 설명)
	- 의미 정보 인코딩을 위한 **텍스트 임베딩** 생성
	- 나중에 쿼리가 주어졌을 시, 검색 할 수 있도록 임베딩을 **데이터베이스**에 저장
	- ![[LLM_2_3.excalidraw]]
- 2단계, 문서 검색
	- 사용자에게 전처리되고 정리할 수 있는 쿼리 존재(사용자가 항목 검색시)
	- 임베딩 유사도를 통해 후보 문서 검색
	- 필요한 경우 후보 문서의 순위를 재순위화(re-ranking)
	- 최종 검색 결과를 사용자에게 반환
	- ![[LLM_2_3_2.excalidraw]]
	- 문서에 사용한 것과 동일한 임베딩 체계를 활용
	- 쿼리를 임베딩하고, 이전에 저장된 문서화 비교
	- 가장 가까운(적합한)문서 반환

### 2.4. 구성 요소

#### 2.4.1. 텍스트 임베더
- Text Embedder
	- 텍스트 문서나 단어 또는 구문을 받아 벡터 변환
	- 벡터는 입력된 텍스트 마다 고유, 구문의 맥락적 의미를 포착
- **텍스트 임베더의 선택**은 텍스트를 벡터로 표현하는 품질을 결정하기 때문에 중요
- LLM으로 벡터화 하는 방법은 아래 방식 모두 존재
	- open source
	- closed source: 예시에서는 openAI의 embedding 제품 사용
- OpenAI의 Embedding
	- 고품질의 벡터를 빠르게 제공할 수 있는 강력한 도구
	- but, closed인 만큼 잠재적인 편향에 대한 제어가 제한적
	- 기반 알고리즘에 접근 불가. 발생하는 문제를 해결하는데 어려울 수 있음

##### 무엇이 텍스트를 유사하게 만드는가
- 텍스트를 벡터로 변환
- 텍스트 조각끼리 얼마나 **유사**한가를 파악 => 수학적으로
- [[코사인 유사도]]
- [[내적]]이나 유클리드 거리와 같은 다른 유사도 지표를 사용할 수 있음
- Open AI의 임베딩 엔진은 특별한 속성 존재
	- 벡터의 크기(길이)는 기본적으로 길이 1로 정규화 => 수학적으로 이점
- 수학적 이점
	- [[코사인 유사도]] = [[내적]]
	- [[코사인 유사도]]와 유클리드 거리는 동일한 순위의 결과 반환
- 즉, [[코사인 유사도]]를 통해서 **의미적으로 두 구문이 얼마나 유사한지**를 알 수 있음