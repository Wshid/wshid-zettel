---
date: 2024-06-25
datetime: 2024-06-25 21:20:15
book: 데이터_품질의_비밀
page:
  - "202"
tags: 
references: 
aliases:
---
데이터 사고 관리, 근본 원인 분석, 포스트모템, 사고 커뮤니케이션의 모범 사례 구축 등
- 운영 환경에서 데이터 품질 문제에 실제로 대응하고 해결하는데 필요한 단계 모색
데이터 사고의 원인을 파악한 뒤에 무엇을 해야 할까?
- 대부분의 데이터 조직, 파이프라인을 일시 중지하고 당면한 문제의 근본 원인 파악 작업은 중요
- 단, 데이터 신뢰성을 보장하고, 다른 팀과의 신뢰 관계를 복원하는데 있어 이런 작업은 **빙산의 일각**

# 6.1. 소프트웨어 개발 시 품질 문제 조정
- 대규모 사고를 관리하고, 해결하는 방법에 대한 아이디어를 얻기 위해
	- [[dev_ops]]와 [[sre]]를 참고할 수 있음
- [[dev_ops]] 라이프사이클
	- 계획: 개발 조직은 소프트웨어 목표와 [[Data_SLA_SLO_SLI#What is an SLA?|SLA]]를 이해하기 위해 프로덕트 및 비즈니스 조직과 협력
	- 개발: 새로운 소프트웨어 코드 작성
	- 빌드: 소프트웨어를 테스트 환경에서 릴리즈
	- 테스트: 소프트웨어 테스트
	- 릴리스: 운영 환경에 소프트웨어 릴리스
	- 배포: 소프트웨어를 기존 어플리케이션과 통합, 배포
	- 운영: 소프트웨어를 실행하고 필요에 따라 조정
	- 모니터링: 소프트웨어의 문제 모니터링, 문제 발생시 경고
- 위 사이클은 반복됨
- 소프트웨어 엔지니어링에서 데이터 환경에 이르기까지
	- 사고 관리의 우수 사례 활용으로
	- 비즈니스 분석 요구사항을 충족할 수 있는 능동적이고 확장 가능한 접근 방식으로 [[data_quality|데이터 품질]]문제 해결 가능
- 효과적으로 사고 관리를 하려면 (소프트웨어) 사고로 인한 운영 중단이 지속되지 않도록 제한하고
	- 가능한 빨리, 중단된 비즈니스를 복구해야 함
	- 잠재적 사고에 대한 대응 미리 준비 x -> 실제 상황에는 원칙에 따라 사고 관리를 하는 것이 소용 없을 수 있음
- 사고 관리란
	- 일상적인 엔지니어링 워크플로에서 발생하는 문제를 식별하고
	- 근본 원인을 파악하며, 해결하고, 분석 방지는 전체 작업을 일컬음
	- 프로그래밍 방식으로 버그가 있는 소프트웨어 운영 중단 및 기타 성능 문제를 실시간으로 발견하고 해결

# 6.2. 데이터 사고 관리
- 데이터 시스템은 수백만개의 서로 다른 이유로 중단 가능
	- 그 이유, 방법을 완전히 이해하는 만능 접근 방식은 x
- 어플리케이션을 다운되지 않도록 관리하듯,
	- 데이터 시스템을 동일한 수준으로 잘 다룰 수 있어야 함
- [[data_pipeline|데이터 파이프라인]]에 [[데이터 신뢰성 라이프 사이클]]을 적용시킴으로써
	- DE는 비즈니스 영향을 미치기 전에 [[data_quality|데이터 품질]]문제를 보다 원활하게 탐지, 해결, 예방 가능
- 파이프라인을 위한 데이터 사고 관리 워크플로 구축시 단계
	- 사고 감지 및 대응, 근본 원인 분석(RCA; root cause analysis), 사고 해결 및 흠 없는 포스트모템(사후 검토)가 포함됨

### [[데이터 신뢰성 라이프사이클]]
## 6.2.1. 사고 감지
- 적합한 툴, 프로세스 사용시
	- 사고 감지를 데이터 엔지니어링 미 분석 워크플로에 통합 가능
	- 데이터 파프라인 전체의 신선도, 볼륨 및 분포 이슈 발생 탐지 가능
- 문제가 발생할 때 모든 데이터 이해관계자와 최종 사용자에게 적절한 **통신 채널**을 통해 경고 가능
- 데이터를 운영 서비스에 입력하기 전 반드시 테스트를 해야함
- 사고 감지
	- 데이터 파이프라인이 손상되거나 대시보드가 고장날 경우 취할 수 있는 첫번째 단계
	- 데이터 모니터링, 알림을 통해 사고 감지 가능
	- 데이터 파이프라인에서 **수동으로 로직을 구현** 하거나 **특정 임곗값을 기준으로 트리거** 가능
- 사고 감지의 요소
	- [[이상 탐지]]
- **데이터 조직이 사고 관리 문제를 '완벽히 해결'하기 위해 [[이상 탐지]]에만 의존하는 경향 존재 -> 이는 문제**
	- 사고 관리는 결코 '완벽히 해결'할 수 있는 대상이 아님
	- 이상 탐지에만 의존하는 것은 장애의 어떤 한 지점만 파악하는 것
- 단, [[이상 탐지]]는 데이터 신뢰성 라이프사이클에서
	- 매우 중요한 부분이며 데이터 사고 관리 프로토콜의 '감지' 단계를 위한 핵심 툴
	- 그러나 테스트, 버전 관리, 옵저버빌리티, 계보, 자동화 친화적인 데이터 조직에서 사용할 수 있는
		- 다른 기술과 프로세스의 추가 지원 없이 **이상 탐지에 의존하는 것은 큰 문제**임
	- 이상 탐지는 도구일 뿐 만병통치약이 아님
- [[이상 탐지]]는 데이터 상태의 핵심 요소(볼륨, 신선도, 스키마, 분포)가
	- 운영 환경에서 기대치를 충족하지 못할 때 이를 파악하고자 하는 조직에 유용함
	- 엔드 투 엔드로 구현하면 비즈니스 측면에서 매우 가치 있음
- 이상 탐지는 필수적인 출발점이나
	- 근본 원인을 파악하고 영향을 평가하기 위해서는 훨씬 더 많은 작업을 해야 함

## 6.2.2. 사고 대응
- 적절한 사고 대응 -> 효과적인 커뮤니케이션으로 시작하고 마무리
- 표준 사고 대응 방법을 설명하는 두가지 방법
	- [[runbook]]
	- [[playbook]]
- 두 방법 모두 파이프라인이 고장 났을 때 팀이 무엇을 해야하는지 도움이 될 만한
	- 코드, 문서, 링크 및 기타 자료를 포함해야 함
- 기존 사이트 신뢰성 엔지니어링 프로그램에는 서비스에 따라 특정 역할을 위임하는 on-call process가 존재
- 사고 대응자 외에 [[사고 책임자]]도 존재
- 메타데이터
	- 비즈니스 관점에서 데이터 다운타임 사고 발생시 영향을 받는 팀 파악시 유용
	- 엔드 투 엔드 계보와 결합하여 영향을 받는 자산 간의
		- Upstream/downstream 관계를 전달하는 것은 쉽고 빠른 프로세스가 될 수 있음
- 일단 [[data_downtime|데이터 다운타임]]이 발생하면
	- 데이터를 사용하는 업스트림, 다운스트림 사용자 모두에게 데이터 다운타임의 영향을 알리는 것이 중요함

## 6.2.3. 근본 원인 분석
- 이론적으로는 쉬우나 현실적으로는 프로세스를 거치기 어려울 수 있음
- 데이터 사고는 전체 파이프라인에 걸쳐 눈에 잘 띄지 않음
	- 여러 테이블에 영향을 미치기도 함
- 대다수의 데이터 문제의 원인은 하나 이상의 이벤트 일때가 많음
	- 시스템에 공급되는 데이터의 예상치 못한 변화
	- 데이터 변환 로직(ETL, SQL, Spark Job)등의 변경
	- 운영 문제: Runtime Error, 사용 권한 문제, 인프라 장애, 예약 변경 등
- [[아마존의 5 Whys 접근법]]
- 시스템은 한 가지 이유로 중단되는 경우는 거의 없음
- 그에 따라 DE들은 프로세스, 테스트, 데이터 신선도 확인 등의 솔루션 마련
	- [[data_observability|Data Observability]] 시스템의 스키마 변경 알림
- 사전에 문제 식별 불가하다면 이 안전장치가 매우 부적절
- [[데이터 파이프라인에서 근본 원인 분석시 데이터 조직이 취해야할 5단계]]
- 근본 원인 분석은 **데이터 품질 문제**를 거의 실시간으로 해결/방지하는데 강력한 도구가 될 수 있으나
	- 파이프라인이 망가졌을 때 특정 문제로 추적할 수 있는 경우는 거의 없음


## 6.2.4. 사고 해결
- 문제가 발생한 것을 확인하고 미칠 영향을 파악했으면
	- (때로는 근본 원인 분석 전에)
	- 그 다음에는 **문제를 해결하고 적절한 이해관계자에게 다음 단계를 전달하는 것**
- 대부분 '초기 해결책'(파이프라인 일시 중지, 서킷 브레이크)가 있음
- '최종 해결책'은 [[data_downtime|데이터 다운타임]] 사고의 근본 원인을 해결하는 것보다 **영구적인 해결책**을 구현하는 것
	- 이때 다양한 이해관계자가 상황을 쉽게 파악할 수 있도록
		- 슬랙 채널, 이메일 타래, 위키 사이트 등 협업 툴을 통해 사건 형태 전달
- 문제가 해결된 후에는
	- 영향을 받는 당사자에게 다음 단계의 일이 무엇인지 전달하고 며칠 내에 포스트모템을 잡아야 함

## 6.2.5. 흠 없는 포스트모템
> 문제는 시스템이지 코드를 작성한 사람이 아니다
> 실수를 허용하지 않는 것이 시스템의 역할이다
- 데이터 파이프라인은 내결함성이 있어야 함
- DE 조직은 문제를 해결하고 근본 원인을 수행한 후에
	- 발생한 사고의 유형이나 **원인에 관계없이 철저하게 교차 가능 [[postmortem]]을 수행**해야 함
- [[postmortem]]을 수행하기 위한 가이드라인

### 모든 것을 학습 경험으로 구성하자
- 건설적인 대화를 위해 서로를 비난해서는 안됨
- 이러한 경험을 **학습 및 개선**이라는 목표를 기준으로 재구성 하기

### 사고 대응 준비 상태를 평가할 수 있는 기회로 활용하기
- [[runbook]]을 업데이트 하고 모니터링, 알림 및 워크플로 관리 툴 조정

### 각각의 [[postmortem|포스트모템]] 결과를 문서화하고 데이터 조직과 공유
- 문서화를 통해 정보 격차 방지
- 지식의 수준 맞추기
- 퇴사자가 발생하더라도 대응 가능

### SLA 다시 확인하기
- [[Data_SLA_SLO_SLI|SLA]]는 많은 기업에서 특정 벤더, 프로덕트, 내부 조직이 제공할 서비스 수준 및
	- 서비스에 실패할 경우 잠재적인 해결책 정의, 측정할 때 사용하는 방법
- 데이터 시스템이 성숙해지거나 변화함에 따라 [[Data_SLA_SLO_SLI]]를 지속적으로 재검토 해야함
	- 6개월 전에 의미 있었던 [[Data_SLA_SLO_SLI|SLA]]가 이제는 더 이상 의미가 없을 수 있음
