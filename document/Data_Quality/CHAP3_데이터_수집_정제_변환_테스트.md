---
date: 2024-05-28
datetime: 2024-05-28 22:30:26
book: 데이터_품질의_비밀
page:
  - "72"
tags: 
references: 
aliases:
---
데이터가 파이프라인에 있기 전과
- 파이프라인에 있는 동안 품질을 관리하는 방법
데이터 실시간 처리 시 사용할 수 있는 **데이터 품질 관리 툴**과 **해당 툴의 이점**을 짚음
[[data_pipeline|데이터 파이프라인]]에서 [[data_quality|데이터 품질]]을 철저히 파악하려면
- 조직에서 지속적으로 운영하는 데이터의 라이프라이클을 **end-to-end**로 살펴보아야 함
데이터 수집 및 정제: production pipeline의 첫번째 단계와 연관
데이터 변환 및 테스트: 데이터 분석을 수행할 수 있게끔 만드는 여정과 관련


# 3.1. 데이터 수집
- 가장 업스트림에 있는 **진입점**
	- 외부 세계의 데이터가 파이프라인에 들어오는 초기 접촉 지점
	- 마치 Docker에서의 Entrypoint
- 진입점의 데이터
	- 그것이 모델링 하는 외부 세계의 전형적인 노이즈, 불규칙성을 모두 포함
	- 제일 원시적
	- e.g. 애플리케이션 로그, 서비스 로그, 클릭 스트림 소스, 라이브 센서, ...
- 데이터 소스는 크게 3가지로 분류됨

## 3.1.1. 애플리케이션 로그 데이터
- 애플리케이션 내의 작업으로 생성된 데이터
- 타임스탬프가 표시되는 이벤트 설명, 애플리케잇녀 소프트웨어 생성 오류, 경고 메세지
- 로그에 포함되거나 불포함 되는 내용이 **개발자**에게 달려 있음
	- 시스템 로그와는 다름
	- 로그 자체가 app 사용에 대한 전체 로그가 아닐 수 있음

### 애플리케이션 로그 데이터 처리시 고려할 점


#### 구조
- app 로그는 단순 **직렬화 텍스트**
	- ASCII 또는 이진 형식으로 사용할 가능성이 높음
- 제약이 거의 없음
- 구조가 매우 다양함

#### 타임 스탬프
- app log text는 `\n`로 구분된 설명이 있는 갭려 이벤트
- 타임스탬프는 이벤트 설명과 달리
	- ISO 표준 형식(`yyyy-mm-ddThh:mm:ss[.mmm]`)이나 유사한 형식으로 표준화 필요

#### 로그 레벨
- 대략적으로 이벤트의 로그 유형 체계화
	- INFO: 순수하게 설명적인 로그
	- WARN: 경고지만 실패는 아님
	- ERROR: app의 프로그래밍 오류

#### 목적
- 로그는 아무렇게나 수집되지 않음
	- 로그 수집 자체도 **비용**이 있기 때문
- 로그를 수집하는 이유?
	- 진단
		- 요청이 얼마나 시간 초과하는가
		- 페이지 로드 속도가 느려지는가
		- 더이상 사용되지 않는 라이브러리를 얼마나 사용하는가
		- 질문에 답변하기 위해 로그를 지능적으로 수집 및 구분 분석 하여 도출
		- 진단 목적으로 로그 데이터 수집시
			- 질문에 대한 답변이 `WARN|ERROR` 로그 일 수 있음
		- 컬렉션의 대부분은 현재 제기하는 **특정 의문**과 관련이 없음
	- 감사
		- 누가 그 요청을 했는가?
		- 몇 번 요청했는가?
		- 시스템은 어떻게 응답했는가?
		- 패턴이 다른가
		- app 내의 이벤트 발생을 기록
		- 대부분의 `INFO`로그가 이 작업에 유용
		- 주로 어플리케이션 세션의 대규모 집계에 활용

## 3.1.2. API 응답
- 하나의 app이 모든 것을 할 수 없기 때문에
	- 특정 기능을 app에 맡김
	- API를 활용
- API는
	- 두 프로그램 사이의 매개체
	- 특정 형식의 **요청**과 **응답**이 필요
	- 목적에 맞는 데이터는 [[반구조화된 데이터]]
- app 로그 외에도 **API Endpoint**에서 가져온 데이터 저장 가능
- 단, 다음 사항에 유의 해야함

### API 응답 사용시 유의점
#### 구조
- 로그처럼 직렬화는 가능하나, **구조화**또는 **반구조화 형식**으로 압축이 풀림
- JSON
	- 우연하지만, 중요한 방식으로 구조에 제약을 받음
	- key-value 혹은 값의 목록
	- 텍스트 스트림일 수도 있는 로그 데이터와 다름
- HTTP
	- HTTP/1.1 와 같은 응답 사양은
	- HTTP 요청 또는 본문에도 JSON|XML 포함 가능

#### 응답 코드
- HTTP 상태 코드
- 다른 코드 표준
	- e.g. HTTP 또는 기타 전송 프로토콜을 사용할 수 있는 `SOAP API`
- 각 코드에는 의미가 있음
	- HTTP 500 응답 속도, 서버 중단 여부를 나타내는 지표
- API 응답 데이터를 저장하는 경우, 이에 대한 고려 필요

#### 목적
- 사용 사례는 API 응답 개체의 어떤 정보가 의미 있는지에 영향을 줄 수 있음
- 특정 상황에서 전송된 정보는 유용하지 않을 수 있음

## 3.1.3. 센서 데이터
- 사물 인터넷 장치, 연구 장비와 같은 센서에서 얻음
- app으로 바로 활용하지는 않음
- 추가로 응용하지 않고 단순히 수집용으로 데이터 전송

### 유의점

#### 노이즈
- 믿을 수 없을 정도로 노이즈가 많음
- 수집 단계에서 초점 x
- 단, 처리량의 중요성은 유의해야 함
- downstream 처리에서
	- 많은 오류값 제거, 평활화 및 기타 변환 수행
- 따라서, 항상 안정적이고 일관된 스트림이 필요

#### 고장 모드
- 센서는 app처럼 똑똑하지 않음
- 센서 실패시 알람을 주지 않을 수 있음
- 수신된 데이터의 양이나, 배치 시간의 시간 [[delta]]와 같은 항목을 영리하게 확인해야 함

#### 목적
- 많은 downstream 작업에 사용
- 오늘날, ML 시스템으로 처리
	- 데이터의 양이 중요할 수 있음
	- 처리량이 중요
- 센서 데이터로 추론 기반 작업시 주의 해야함
	- e.g. 문 앞에서 움직임 감지시 알람 -> 작업의 대기시간이 중요

# 3.2. 데이터 정제
- date cleansing
- 사용 가능한 데이터셋에서 부정확하거나, 대표적이지 않은 데이터 제거
- 데이터 처리 및 데이터 프로덕트 개발 상태에 따라 다양한 종류 존재

### 오류값 제거
- 이상값 제거
	- 표준점수(z점수)와 같은 통계적 기술
	- [[Isolation forest]]와 같은 알고리즘 적용
- 데이터 셋이 큰 경우, 문제 해결 절차에 걸리는 **시간 복잡도**에 유의해야 함

### 데이터셋 특징 평가
- 수집한 데이터의 모든 내용이 다운스트림과 연관 없을 수 있음
	- 그런 섹션은 제거할 것
- 불필요한 데이터 필드 수집은
	- 스토리지 비용 발생
	- 히스토리 추적시 어려움
	- 도메인 지식의 불필요한 확장
	- 분석 복잡도 증가
	- 데이터 품질 저하

### 정규화
- 일부 데이터 포인트는 독립적으로 검사 가능
- 특정 데이터 포인트는 다른 데이터와 비교시 의미 있음
	- 이 경우 정제 및 변환 단계에서 데이터를 정규화 하는것이 도움이 됨
- 정규화에서 자주 사용되는 선택지
	- L1(Manhattan) 정규화
	- L2(Unit) 정규화
	- 평균차분(demeaning) 및 단위 분산
- 최상의 선택이 무엇인지는 데이터 사용 사례에 따라 달라짐

### 데이터 재구성
- 수집한 데이터의 특정 필드 누락
	- cause. 오류 발생이 쉬운 API, 오프라인으로 전환되는 센서
- 일반적으로 누락은 이슈가 없으나, 경우에 따라 모든 필드에 값 지정 필요
	- [[Interpolation|종종 보간법]]
	- [[Extrapolation|외삽법]]
	- 서로 비슷한 데이터의 범주화/분류 등의 기법 사용
		- 기본 수준 범주 레이블 지정 및 자동 식별
			- https://digital.lib.washington.edu/researchworks/handle/1773/43082
- 약간의 노이즈가 포함되겠지만, 오류값 대체 가능

### 시간대 변환
- 표준 시간대 변환, 일종의 정규화로 간주 가능
	- 하지만 시간대 변환 자체가 중요하기 때문에 별도 토픽으로 구성
- 대부분 UTC라는 하나의 기준으로 정리
	- UTC는 표준 시간이지, 시간대는 아님
	- 그리니치 표준시(GMT)를 사용하는 국가는 UTC를 인정하나, 사용하지는 않음
- 시간대 변환 없이 시간대 정보만 수집한다면,
	- 2개의 국제적인 사건 발생시 알기 어려움
- 소프트웨어 버그는 시간대 혼동(e.g. Y2K)으로 추적될 수 있으므로
	- 시간대를 주의 깊게 살펴 UTC로 변환/지정되는지 확인 필요

### 유형 변환
- 대부분의 정형화된 데이터는 유형이 지정됨 => 특정 형식을 따라야 함
	- 하지만 컴퓨팅에서 app이 작동하려면, 형식 변화에 **유동성**을 부여하는 경우가 많음
		- e.g. 부동소수점 => 정수, 문자 => 문자열
- downstream에 특정 유형의 데이터 필요한 경우
	- **정제 프로세스**의 일부로, 한 데이터 유형에서, 다른 데이터 유형으로 값을 **자동**또는 **암시적**으로 변환하는 형식 고려 필요
- 유형 변환은 다른 형식의 데이터 결합하는 경우에도 필수적

# 3.3. 배치 처리 vs 실시간 처리
- 배치 처리
	- 일정 기간 동안 데이터 수집
	- 다량의 데이터를 별개의 패킷으로 '배치'
	- Apache Hadoop
		- 분산 저장 및 대용량 데이터 처리
	- Google BigQuery, Snowflake, Microsoft edge, Amazon redshift
- 실시간 처리
	- 프로세스는 길지만 데이터를 즉시 처리
	- **Apache Kafka**, Amazon Kinesis
	- **Spark**, Flink, Storm, Samza, Flume
	- Databricks, Cloudera

# 3.4. 실시간 처리를 위한 데이터 품질
- 배치 처리와 실시간 처리의 주요 차이점
	- 배치당 처리되는 데이터의 양, 처리 속도
- 배치 처리
	- 지연이 발생하더라도 최대한 많은 양의 데이터를 수집
	- 데이터 품질이 상대적으로 높음
		- 파이프라인에서 주어진 단계에서 데이터의 상태
- 실시간 처리
	- 가능한 한 빨리 데이터를 수집
	- 손실 발생 가능
	- 데이터 품질이 실시간으로 스트리밍 시 오류에 따라 상대적으로 중요함
- 실시간 처리에서 사용되는 데이터 품질 문제를 해결하는 방법?
	- 기존에는 **테스트**를 통해 데이터 품질을 관리
	- 데이터에 대한 가정을 기반으로 작성하나, 모든 결과 설명 불가능
- **테스트는 확장하기 어려웠음**
	- 데이터 품질 문제의 약 20%만 해결 가능했었음
	- [[알려진 미지]]가 존재함
- 아파치 키네시스와 카프카를 활용하여 실시간 처리 시스템의 데이터 품질 관리하기

### [[Amazon Kinesis]]

### [[Apache Kafka]]

스트리밍 시스템의 높은 대기 시간을 고려할 때
- 스트리밍 입력을 다운스트림 시스템으로 직접 **스트리밍**가능
- 단, 이 유형의 분석 데이터는 더 많은 오류를 발생 시킴
- 실시간 또는 거의 실시간으로 이를 이해하는 것이 어려움
	- 분석 사용 사례에 종종 **배치 처리**를 선택하는 이유

[[Apache Kafka|아파치 카프카]]나 [[Amazon Kinesis|아마존 키네시스]] 중에 선택하는 이유는, 조직 요구사항에 따라 달라짐
- SaaS 선호시 키네시스
- 대규모, 구체적인 요구사항시 카프카

데이터 품질 관리를 위해 첫번째 단계는 데이터 정규화임


# 3.5. 데이터 정규화
- 첫 운영 데이터 변환 레이어 => 데이터 정규화 단계
	- 조직에 따라 다르게 붙일 수 있음
- 데이터 변환
	- 소스 형식 -> 목적지 형식, 데이터 이동
- 노이즈, 모호성, 이질성이 최대인 **진입점 데이터**에서 정규화 발생
- 특별히 고려해야할 점이 있음

## 3.5.1. 이종 데이터 소스 처리

### 정규화 지점에서의 데이터 설명
#### 대기 시간 최적화
- 생성 즉시 사용할 수 있도록
- 최종 상태와 상관없이 즉시 파이프라인으로 푸시됨
	- 데이터 배치는 불완전할 것으로 예상해야 함

#### 비위계적인 형식
- 효율성과 사용 편의성을 위해
	- 비위계적이고, 수평적인 스토리지 형식으로 저장
- 깨끗한 창고 + 스키마 + 테이블 x
- S3 버킷과 같은 일부 중앙 저장소에 데이터를 dump할 가능성이 높음

#### 원시 파일 형식
- 진입점 데이터 수평적으로 저장될 뿐 아니라, 스트리밍된 위치에서 원래 파일 형식을 반영할 수 있음
- 애플리케이션 로그 데이터, 센서 데이터를 표 형식으로 변환할 필요 x
- 이는 비쌀 뿐만 아니라, 데이터는 이러한 변환이 필요하지 x

#### 선택적 데이터 필드
- [[data_warehouse|데이터 웨어하우스]] 데이터와 달리
	- JSON과 같은 원시 데이터들은 **선택적 필드**를 가질 수 있음
- 해당 필드의 부재가 `NULL`인지 숫자 `0`인지 등을 추론해야 할 수 있음
- 해당 필드에 따라 기본값이 될 수 있으며
	- 해당 필드가 없는 경우 upstream 처리에 문제가 될 수 있음

#### 이질성
- 위의 모든 특징은 특정한 종류의 **이질성**을 가리킴
- 데이터는 다양한 원본 파일 형식, 다양한 소스로부터 제공되며
	- 동일한 형식의 이진 데이터와 비교하여 처리된 양이 다를 수 있음
- 예측 가능한 종류의 이질성에 대비하여 데이터를 이해하는 것이 이 단계의 핵심
	- 일단 데이터가 저장되고 처리되면, 데이터를 쉽게 변환하여 최대한의 영향을 줄 수 있도록 보장해야 함

##### 이질성 측면: [[data_warehouse|데이터 웨어하우스]] vs [[data_lake|데이터 레이크]]
- 위에서 언급된 내용 대부분 데이터 레이크 형식의 데이터를 설명
- [[data_lake|데이터 레이크]]는 수용할 수 있는 데이터 유형에 대한 제약이 적음
	- 진입점 데이터가 선호하는 스토리지 솔루션 일 수 있음
- 따라서 스트리밍 서비스([[Amazon Kinesis|아마존 키네시스]], [[Apache Kafka|아파치 카프카]])가
	- 서로 다른 소스 위치에서 **비구조화** 및 **반구조화** 데이터를 수집하여
	- 데이터 레이크에 저장한 다음
	- 다음 초기 수준의 운영 변환에 의존하여 이 데이터의 일부를 웨어하우스에서 정형화된 형태로 가져옴
- [[Amazon Kinesis|아마존 키네시스]]용 AWS 람다 함수, [[Apache Kafka|카프카]]스트림즈용 아파치 카프카 소비자가
	- 이러한 종류의 정규화를 적용하는 대표적인 방법
- [[AWS 글루]]는 정기적으로 데이터를 [[data_warehouse|데이터 웨어하우스]]로 이동하는 단계에서 유용함

## 3.5.2. 스키마 검사 및 유형 변환
- 스키마 검사, 유형 변환 - 데이터 정규화에 적용하고자 하는 두가지 기술

### 스키마 검사
- 데이터의 구조가 우리가 기대한 그대로인지 검증하는 과정
- 필수 필드가 있으며 요구하는 형식 데이터가 포함되어 있는가?
	- [[형식 강제]]
- 스키마를 확인해야 하는 이유?
	- 데이터는 패키지 형식으로 제공되는 경우가 많음
	- JSON, CSV 등
- 스키마는 처음으로 데이터를 **패키지 해제** 할 때 무엇을 기대해야 하는지 알려줌
- 스키마 변경은 **데이터 손상의 주요 원인**
- 변경에 따라 발생할 수 있는 오류는 사전에 확인해야 함
	- 예상되는 스키마와
	- 여기에 생길 수 있는 가시적인 변화를 계속 기록하는 작업

### 유형 변환
- 데이터 오류를 일으킬 수 잇음
- 일부 app에서는 오류를 발생시키지 않고
	- 형식을 강제로 지정하거나 암시적으로 캐스팅 할 수 있음
- 문자열 `"4"` -> 정수 `4`: 큰 문제는 아님
- 부동 소수점 `4.00` -> 정수 `4` 문제 발생
- 기본적인 듯 하나 악의적인 버그 발생 가능성 존재

## 3.5.3. 데이터의 구문론적 모호성과 의미론적 모호성
- 데이터의 모호함: 특정 방식으로 중요하게 나타남
- [[구문론적 모호성]]
- [[의미론적 모호성]]

## 3.5.4. 아마존 키네시스 및 아파치 카프카 전반에 걸친 운영 데이터 변환 관리
- 운영 데이터는 원시 상태에서 데이터를  처리하지만,
	- 완전히 맹목적으로 처리해야한다는 의미는 아님
- 많은 데이터 스트리밍 처리 app에서는
	- 기본 제공 알림
	- 필요에 따라 더 복잡한 알림을 구성할 수 있음
- 일반적으로 **운영 변환 단계**에서 수행하는 검사는 이 단계에서 **지연 시간 초과 처리량**에 대한 우선순위와 일치함
- 즉, 이 단계에서는 **데이터 드리프트**와 같은 처리량 집약적인 집계 검사를 피할 수 잇음
	- 대신, 수신 스키마와 과거 스키마를 비교하거나
	- 시간에 따라 검색되는 바이트 볼륨을 추적하는 등
	- 지연 시간이 짧은 검증을 모니터링 목표로 설정해야 함
- 여기서 수행되는 많은 운영 '모니터링'은
	- 수신 데이터가 기존 용량, 스토리지 및 메모리 제약을 초과하지 않도록 하는데 초점을 두기 때문에 [[data_quality|데이터 품질]]을 보장하지 않음

#### [[Amazon Kinesis|아마존 키네시스]]
- [[AWS lambda]]기능을 통해 관리
- 다양한 **전처리**작업을 위해 람다 구성 가능
- 그 편재성을 위해 해당 **전처리**에 일부 데이터 품질 보증을 내포할 수 있음
- `.Net, Go, Java, Node.js, python, ruby`로 작성할 수 있음
- aws console에 업로드만 하면 호출됨
- 실행중인 amazon kinesis instance에 lambda를 연결하려면
	- `connect to a source`
	- `Record preprocessing with AWS Lambda`
- app SQL 코드가 실행되거나 
	- 아마존에 들어오는 데이터의 스키마 스냅샷을 만들기 전에 실행되는
	- 새로운 람다 함수를 만들 수 있다

#### [[Apache Kafka|아파치 카프카]]
- kakfa streams 및 다양한 producer, consumer를 위한 세분화된 설정을 제공함ㄴ
- confluent, instcluster 및 aws가 제공하는 강력한 스트리밍 프레임워크 사용
- [[data_downtime|데이터 다운타임]] 방지를 즉시 처리
- [[data_quality|데이터 품질]]을 위한 다양한 구성 가능성을 제공함
	- [[Schema Registry]]
- kafka stream은 JMX를 통해 **스트리밍 메트릭**을 보고함
	- [[Jconsole]] 활용 가능
- kafka streams java class instnace에서 `KafkaStreams#metrics()` 메서드를 사용하여 메트릭 액세스 가능


# 3.6. 분석 데이터 변환 실행
- [[분석 데이터 변환]]
- 분석 데이터는 몇 가지 측면에서 운영 데이터와 상이함

## 3.6.1. ETL 과정의 데이터 품질 보장
- ETL: 분석 데이터 변환과 동의어로 사용
- ETL: '추출-변환-적재'를 의미
	- 복잡한 데이터를 가진 조직에서 점점 더 보편화되고 있는 3단계 프로세스를 설명
- 추출
	- 일부 업스트림 소스에서 원시 데이터를 내보내고 준비 영역으로 이동
	- MySQL, NoSQL, CRM 시스템, 데이터 레이크 원시 파일
- 변환
	- 준비 영역의 데이터가 데이터 엔지니어의 사양에 따라 결합되고 처리
	- 어떤 경우에는 단순 소스 데이터 복사하는 경우도 존재
	- 어떤 경우에는 변환 집중도가 높을 수 있음
- 로드
	- 변환된 데이터를 [[스테이징 영역]]에서 대상(대개 데이터 웨어하우스의 특정 테이블)로 이동

## 3.6.2. 변환 과정의 데이터 품질 보장
- ETL, ELT의 '변환' 단계는 가장 집약적일 수 있음
- [[ETL]]
- [[ELT]]
- [[ETL]]은 DE가 데이터를 **프로덕션**으로 이동하기 전 검증할 수 있는 기회 제공
	- 단, 데이터를 보다 신속하게 처리하고 테스트 및 모니터링을 적절히 수행하지 않을 경우 데이터 품질 하향

### 소스 데이터를 변환하는 이유
- 스키마 요구 사항에 맞게 필드명 변경
- 소스 데이터 필터링, 집계 및 요약, 중복 제거, 정제 및 통합
- [[유형 변환]] 및 단위 변환 수행
	- e.g. 서로 다른 통화 필드를 모두 미국 달러와 부동 소수점 유형으로 표준화
- 중요한 데이터 필드나 업계 또는 정부 규종을 충족하기 위한 암호화
- [[데이터 거버넌스]] 감시, [[data_quality|데이터 품질]]검사 수행

# 3.7. 테스트 및 경고 알람 시스템
- dbt, wherescape 또는 인포메티카와 같은 ETL 시스템도 오류가 발생하기 쉬움
- 대량 생산 환경에서 이러한 app 수행시
	- 강력한 테스트, 알람 시스템 필요
- 데이터 변환 시스템에는 대부분 데이터 품질을 위한 매커니즘이 내장됨
- 

## 테스트와 데이터 테스트

### 테스트
- 단위 테스트
- 파이프라인 상태에 대한 가시성 메트릭
- 경고

### 데이터 테스트
- 프로덕션 데이터 파이프라인에 들어가기 전
- 데이터 품질 문제를 발견하는데 중요한 역할을 함
- 데이터에 대한 조직의 가정을 검증하는 프로세스
	- **생산 전 또는 생산 중**에 수행
	- e.g. 고유성, `NULL`이 아닌 것을 확인하는 기본 테스트 -> 조직이 소스 데이터에 설정한 기본 가정 테스트 가능
- 데이터가 데이터 조직이 작업할 수 있는
	- 올바른 형식인지, 비즈니스 요구 사항을 충족하는지 확인 가능

### 가장 일반적인 데이터 품질 테스트
- NULL 값 여부
- 용량
	- 데이터를 전부 받았는지
	- 너무 많이 받았는지
	- 너무 적게 받았는지
- 분포
	- 데이터가 허용 범위 내의 값인지
	- 값이 지정된 열의 범위 내에 있는지
- 유니크함
	- 중복된 값이 있는지
- 정보 불변속성
	- 두 개체는 근본적으로 다른지
	- e.g. 순수익 = 매출 - 비용 인가

### 데이터를 테스트하는데 적합한 도구?
- dbt test, great expectations
- 이해 관계자에게 전달하기 전, 데이터 품질문제를 발견하는데 사용

### 데이터 품질 테스트를 위한 사전 작업
- 변화된 데이터를 임시 준비 테이블/데이터셋에 로드
- 테스트를 실행하여 **스테이징 테이블**의 데이터가 운영에 필요한 **임계값**내에 있는지 확인

### 데이터 품질 테스트에 실패하면
- 해당 자산을 담당하는 [[data_engineer|데이터 엔지니어]]나 [[data_analyst|데이터 분석가]]에게 경고가 전송되고 파이프라인은 실행되지 않음
- 이를 통해 데이터 엔지니어는
	- 최종 사용자, 시스템에 영향을 미치기 전에
	- 예상하지 못한 문제 파악 가능
- 데이터 테스트는
	- **변환 전**과 **변환 프로세스**의 각 단계 이후에 수행 가능


## 3.7.1. dbt 단위 테스트
- `dbt run`: 모델 변환
- `dbt test`: 변환된 모델에 대해 단위 테스트
	- 사용자 지정 sql 쿼리 정의
	- `yml` 스키마 파일 내 개별 모델 할당
- dbt 단위 테스트
	- 실패한 행을 가져오도록 설계됨
	- e.g. 테스터의 주장과 일치하지 않는 레코드
- `assert`하는 SQL의 일반적인 테스트 패러다임
	- 유연하고 효과적이나 한계가 있음
- 단위 테스트, 통합 테스트 => dbt를 사용할 때 모호해짐
- dbt 모델: 독립 실행형 SQL문
	- 입력 데이터를 가져와 변환 적용. 변환 결과를 대상 테이블에 로드
	- 이 변환 로직은 독립형 방식으로 실패 가능
		- 각 dbt 모델의 품질을 개별적으로 평가하는 '단위 테스트'
- 동시에 dbt(및 실제 모든 ETL) 모델은
	- 긴 변환 시퀀스 내에 있으므로
	- 전체 파이프라인에 대한 통합을 테스트 하는 것도 합리적
- 따라서 동일한 `tests` 저장소에서
	- dbt 모델에 대한 단위 테스트와 통합 테스트를 모두 작성할 수 있음
	- **이때 문서화가 핵심**
- dbt 테스트의 종류 두가지

### 단일 테스트
- 특정 모델을 참조하는 독립 실행형 SQL 테스트
- SQL로 작서하는 단일 테스트를 테스트 디렉터리에 저장시, dbt 테스트 호출시 실행됨

### 일반 테스트
- 여러 모델에서 재사용할 수 있는 `templatized` 테스트
- 매개변수화된 SQL 쿼리 형식을 취함. 인수 사용 가능
- `yml` 스키마 파일에서 특정 모델에 대한 일반 테스트 적용 가능
	- 열 이름 혹은 threshold/SLA 매개변수 입력 가능
- 예시: NULL을 확인하는 일반 테스트
```yaml
-- tests/test_not_null.sql
{% test not_null(model, column_name) %}
	select *
	from {{ model }}
	where {{ column_name }} is null

{% endtest %}
```
- dbt는 4가지 기본 일반 테스트 수행
	- `unique`
	- `not_null`
	- `accepted_values`: 열에 대한 모든 값이 유한 집합중 하나임을 보장
	- `relationships`: 참조 무결성 확인
		- 기본적으로 id와 같은 중요 필드에 대한 1:1 대응 보장
- dbt test는 일반적으로 `ELT`에 대한 테스트 표준으로는 훌륭하나, 몇 가지 제약 사항 존재

### DBT 제약사항

#### 기술 부채 및 유지
- `dbt test`의 경우, 개발자가 코드 형태로 수동 관리
- 모델 자체의 업데이트는 해당 모델에 대한 테스트 업데이트를 의미
- 복잡한 테스트
	- 고품질 데이터를 보장하나
	- 엔지니어링 리소스에 시간을 많이 들여야 함

#### 테스트 피로 및 암묵적 지식
- 테스트 실패가 실효성을 지니려면 '의미가 있어야 함'
	- 그러지 않을 경우, 제대로 갖춰지지 않은 모델에 테스트된 코드를 추가할 수 있음
	- 또 다른 개발자가 추후에 테스트 중단할 수 있음
- 테스트가 수행된 이유를 이해할 수 없는 경우
	- CI 빌드 완료 이후 타켓을 사용할 수 있도록 테스트를 제거할 수 있음
- 이렇게 되면 테스트는 개발을 완료하기 위해 극복해야하는 장애물이됨
	- 모델 성능에 대한 통찰력 제공과 무관해짐
- 위와 같이 테스트가 수행되지 않도록 해야함
- 잘못된 테스트는 **데이터 품질에 아무런 도움이 되지 않음**
	- 개발자의 작업속도 저하
- 이 문제를 진지하게 받아들일 생각이 없다면 차라리 테스트를 하지 않는 것이 나음

#### 제한된 가시성
- `upstream` 문제로 인해 `dbt test`가 실패할 수 있음
- 이 때, 테스트는 무언가를 잘못됨을 나타내기 때문에 좋은 신호이나
	- 빠른 해결책을 제공하지는 못함
- `ELT 테스트 체계`가 end-to-end로 진행되지 않았음을 의미하기 때문에
	- 버그를 제거하려면 스택을 전체적으로 다시 점검해야 함

## 3.7.2. 그레이트 익스펙테이션즈 단위 테스트
- 단위 테스트의 형태로 '기대되는 것을 파악' 할 수 있는 다른 방법 제공
- test가 python으로 작성되어 dbt보다 확장성이 뒤어나고
	- ELT/ETL 솔루션에 적용 가능
- 단일 소규모 데이터 배치부터 전체 변환에 아우르는
	- 다양한 데이터 불륨 범위에서 단위 테스트 실행 가능
- 테스트 적용 이후 `Data Doc`이라는 사람이 읽을 수 있는 결과 페이지 제공
	- 다양한 테스트의 실패율에 대한 유용한 분석 제공
	- 실패한 행을 무작위 샘플링 하여 보여줌

### 일반적인 사용 편의성
- 단일 yaml로 소스 관리
- 데이터 검증을 위한 jupyter notebook 환경 사용

### 슬랙 연동
- 유효성 검사 단계 완료시 slack alert을 받을 수 있음

### 파이썬으로 제한된 사용
- SQL, R 등 사용 불가

### 변환/작업 오케스트레이션 도구와 분리
- DE 스택의 transformation(e.g. dbt model) 및 orchestration(dbt cloud) 조각과 밀접하게 연결된 dbt 단위 테스트와 달리,
	- GX는 학습 곡선이 완전히 다름
- Data Docs에서 분석을 제한적으로 사용하거나, 테스트에서 광범위한 사용자 지정 사용시
	- dbt 테스트와 같이 통합된 것을 선호할 수 있음
## 3.7.3. Deequ 단위 테스트
- AWS에 의해 구축된 오픈소스 라이브러리
- 데이터에 대한 단위 테스트 실행
- Apache Spark 위에 구축되어 포맷 유연성이 좋음
	- Spark DF에 들어갈 수 있는 csv, json, table on DW, app log data
- PyDeequ 패키지 지원(Github, PyPI)
- dbt test, GX와 마찬가지로
	- 테스트 조건을 주장하고 실패한 행 또는 데이터 배치를 반환함
- AWS 변환 및 스트리밍 환경에 통합 가능
	- app 불량 테스트를 upstream에 공급하기 전 '검역'(quarantine)하도록 설계
- 테스트 외에도 배포를 위한 더 나은 통합 도구가 될 수 있음

### 실질적인 Deequ 테스팅
- 진입점: `VerificationSuite` 클래스
- `VerificationSuite` 객체를 사용하여 `.onData(data)`에 테스트할 데이터를 할당하고,
	- `addCheck()`를 사용하여 개발 단위 테스트 `Checks`를 추가할 수 있음
- e.g. 테스트한 데이터가 특정 크기를 가지고 있고,
	- 고유하고 `NULL`이 아닌 열이 있으며, 적절한 범위 내의 분위 수가 있는지 테스트 가능
- 호출시 Deequ는 `VerificationSuite`를 일련의 Spark 작업으로 전환

#### 더미 데이터 집합에 대한 단순 단위 테스트 정의
```scala
import ...

val verificationResult = VerificationSuite()
	.onData(data)
	.addCheck(
		Check(CheckLevel.Error, "unit testing my data")
		.hasSize(_ == 5) // 5개의 row
		.isComplete("id") // is not null
		.isUnique("id") // unique
		.isComplete("productName")
		.isCertainedIn("priority", Array("high", "low")) // high, low만 존재하는가
		.isNonNegative("numViews") // > 0
		.containsURL("description", _ >=0.5) // description의 절반 이상은 URL 포함
		.hasApproxQuantile("numViews", 0.5, _ <= 10) // item의 절반은 10 view 보다 낮아야함
	)
```

### Deequ의 장점
- AWS 연동
- 뛰어난 확장성
	- scala로 수행시 scala 작업 orchestration 및 병렬 처리 활용 => 효율성 증가
	- 데이터는 scala DF에 저장
- Stateful 계산
	- metric metadata 계산 후, 해당 메타데이터를 제자리에 저장 한 후
		- 더 많은 데이터가 수집될 때 주요 메트릭 재계산 가능
	- 메트릭 계산에 대한 점진적인 접근 방식
		- 전체적으로 다시 계산할 여유가 없는 데이터셋으로 작업 가능
	- 대규모 스트리밍 데이터셋에 유용
- 이상 탐지 기능 내장
	- 고급 이상 탐지를 위한 내장 기능
	- c.f. GX는 변화율, 단순 임곗값을 기반으로 이상을 '탐지'하도록 구성
	- Deequ는 조금 더 자세히 실행중인 **지표 평균 및 편차** 탐지 가능

### Deequ의 단점
- 스칼라의 학습 곡선
- 통합 테스트로서는 제한된 적용 가능성
	- dbt의 경우 모델별로 수행 및 ELT 파이프라인 전체에서 testing method 통합
	- but, deequ는 사용자가 제공하는 모든 데이터 배치에서 유연하게 실행됨
	- deequ는 통합 테스트 소프트웨어는 아님
	- 통합 테스트와 유사하게 사용하려면 비용이 듦
- 직관적인 UI 부족
	- 기능적으로 DE 니즈를 만족시킴
	- GX의 Data Docs, Slack alert 등이 지원되지 않음

# 3.8. 아파치 에어플로를 활용한 데이터 품질 관리
- 데이터 파이프라인 전반에서 워크플로를
	- 프로그래밍 방식으로 작성, 예약 및 모니터링하는 조정 레이어에서
	- 데이터 품질을 보다 효율적 관리 가능
- 워크플로의 여러 '체크포인트'를 고려할때(DAG)
	- 데이터 구조에 장애 발생 및 잘못된 변경이 일어나는 상황은 사실 흔함
- 아파치 에어플로 DAG의 일반적인 다운타임 유형
	- 쿼리 성능 저하 및 잘못된 파이썬 코드
	- 아파치 에어플로 작업이 실행되나 예상보다 오래 걸릴 때 쿼리의 질이 악화됨
	- 일반적으로 파이프라인이 확장되지 않는다는 의미
- 에어플로에서 작업에 소요되는 최대 시간 동안 SLA 예약 가능
	- 작업이 오래 실행되면 apache airflow UI에서 'SLA 누락'으로 표히되거나
	- slack, ms teams, email 등 선호하는 채널을 통해 통신 가능

## 3.8.1. SLA 목록
- apache airflow task의 SLA 설정시
	- `datetime.timedelta` 개체를 SLA 매개변수에 전달해야 함

### sla_miss_callback
- `sla`에 관한 자체 로직 수행시 `sla_miss_callback`을 포함할 수 있음
	- sla 누락시 발생시 트리거
	- `dag, task_list, blocking_task_list, slas, blocking_tis`
- 데이터 파이프라인이 특정 SLA를 충족하지 않는 경우 일시 중지 가능
```python
@dag(
	 schedule_interval='...',
	 sla_miss_callback=sla_callback, # 따로 메서드 구현 필요
	 
)
def example_sla_dag():
	@task(sla=datetime.timedelta(seconds=10))
	...
```

### CircuitBreaker
- 실행중인 데이터 파이프라인에 서킷 브레이크 방법론 적용
	- 데이터 품질 임곗값들을 충족하지 못할 때, 파이프라인 작동을 중지해 버리는 것
- 일반적으로 CI/CD 워크플로에서 새로운 소프트웨어 배포로 인해
	- 시스템이 중단되는 것을 방지하는 수단으로 사용
	- 데이터 파이프라인에도 동일 개념 사용 가능
- 버전 관리와 같이 CI/CD 프로세스의 테스트 및 기타 단계에 서킷 브레이커 통합 가능

#### 예시
- e.g.1. downstream 작업을 수행하기 전 무결성 테스트를 실행하기 위해
	- 메트릭 업데이트 완료 이후 서킷 브레이커 구현
	- 최근 메트릭에서 데이터 다운타임이 발생하는 경우 false positive가 데이터 분석가, 과학자에게 전송되는 것을 방지할 수 있음
- e.g.2. 파이프라인에 공급되는 upstream 데이터가 부정확한 것으로 판명될 경우
	- 파이프라인 중간에서 데이터 워크플로를 일시 중단

#### 서킷 브레이커의 두가지 패턴
- 고품질 데이터와 저품질 데이터가 혼합되는 것을 방지함
	- 서킷 폐쇄: 데이터가 파이프라인을 통해 흐름
	- 서킷 개방: 데이터가 파이프라인을 통해 흐르고 있지 않음

#### 서킷 브레이커를 사용하기 위한 솔루션
- 데이터 계보
- 파이프라인 전반의 데이터 프로파일링
- 프로파일링을 통해 발견된 문제를 통해 서킷을 자동으로 트리거

## 3.8.2. 아파치 에어플로를 활용한 서킷 브레이커 설치
- DAG에 서킷 브레이커를 설치하면 조정 레이어에서 실제로 데이터 파이프라인을 중지하여 데이터 품질 문제 예방 가능
	- 새로고침 프로그램, 볼륨 및 스키마 임곗값 요구 사항 미충족 등
- 서킷 브레이킹은 나쁜 데이터가 완벽하게 양호한 파이프라인을 손상시키는 것을 방지할 뿐만 아니라,
	- 데이터 품질 문제가 있는 DAG가 시행될 때 소모된 부분을
	- 다시 메울 필요가 없도록 보장함
- 빠르게 움직이는 데이터 조직에서 서킷 브레이커는 잠재적으로 비용을 절감할 수 있음
	- 하지만 가장 중요한 데이터 다운타임 사고에만 사용되는 경우가 많음
- 이후 다음절에서 일반적이고 능동적으로 데이터 품질을 관리하는 방법은 **SQL 검사 연산자** 제안
### DAG를 서킷 브레이킹 하는 방법
- `catchup=False`
- `LatestOnlyOperator` 연산을 포함하여 DAG 실행 중지
- 맞춤형 파이썬 코드를 Orchestration Layer에 삽입하여 '중단'하게 만들고
	- Data Observability Platform 혹은 Data Catalog에서 직접 근본 원인 분석과 관련된 메타 데이터 표시


## 3.8.3 SQL 검사 연산자
- DAG 또는 전체 데이터 파이프라인에서 데이터 품질을 **수동**으로 검사하는 방법
- Great Expectations, dbt, 기타 데이터 품질 테스트와 동일한 방식으로 작동
	- 지정된 DAG의 내용이 값, 간격, 임계값을 비롯한 여러 주요 요소에 걸쳐 기대치와 일치하는지 확인
- Apache Airflow를 사용하면
	- 지정한 SQL 쿼리에서 단일 행을 반환하는 **사용자 지정 SQL 검사 연산자**를 실행
	- 해당 행에 반환된 값이 `False`인지 확인 가능
- SQL 검사 연산자 예시
```python
SQLCheckOperator(
				 task_id='orange_carddata_row_quality_check',
				 sql='row_quality_blue_bankdata_check.sql',
				 params={'dropoff_datetime': '2021-01-01'}
)
```
- 서킷브레이커와 유사하게 테스트를 통과하지 못할 경우 파이프라인 중단
### 파이프라인 중지의 위험성
- '파이프라인 중지'는 회사에 심각한 영향을 미칠 수 있는 데이터 사고에만 적용해야 함
- 전략적이고 신중하게 구현하지 않으면
	- 서킷 브레이크 및 SQL 검사 연산자 때문에 완벽한 품질로 잘 작동하는 **전혀 관계없는 작업**을 멈추게 할 수 있음
- 또한 이로 인해 분석 데이터가 다운스트림 시스템으로 이동하지 못하도록 막는 결과 초래 가능

# 3.9. 마치며
- [[data_downtime|데이터 다운타임]]을 관리한다는 것
	- 다운스트림 대시보드에서 오류값을 발견했을때 이해관계자에게 응답하는 경우 x
	- CEO에게 '데이터 누락을 확인하라'며 미친듯이 쏟아지는 이메일을 받고 snowflake 쿼리를 확인하는 것을 의미하지는 x
- 데이터 파이프라인의 각 단계의 [[data_warehouse|데이터 웨어하우스]], [[data_lake|데이터 레이크]], 비즈니스 인텔리전스 레이어까지
	- 데이터 품질 검사를 통합해야만 다운타임을 예방할 수 있다
- 기술만으로는 데이터 품질을 해결할 수 없으나, 신뢰성을 염두에 두고
	- 데이터를 수집, 정제, [[ingestion]], 처리, orchestration 하는 것이 확실히 도움이 될 수 있음
- 3장에서 제시한 다양한 기술을 사용하면
	- 데이터에 대한 가정이 현실과 맞지 않을 때 적극적으로 상황 식별이 가능하고
	- 사고가 일어났을 때 적절한 통합과 사용자 정의를 통해
		- **적절한 통신 채널**로 경고 신호를 보낼 수 있음