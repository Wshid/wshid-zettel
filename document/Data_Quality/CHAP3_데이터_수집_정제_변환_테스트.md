---
date: 2024-05-28
datetime: 2024-05-28 22:30:26
book: 데이터_품질의_비밀
page:
  - "72"
tags: 
references: 
aliases:
---
데이터가 파이프라인에 있기 전과
- 파이프라인에 있는 동안 품질을 관리하는 방법
데이터 실시간 처리 시 사용할 수 있는 **데이터 품질 관리 툴**과 **해당 툴의 이점**을 짚음
[[data_pipeline|데이터 파이프라인]]에서 [[data_quality|데이터 품질]]을 철저히 파악하려면
- 조직에서 지속적으로 운영하는 데이터의 라이프라이클을 **end-to-end**로 살펴보아야 함
데이터 수집 및 정제: production pipeline의 첫번째 단계와 연관
데이터 변환 및 테스트: 데이터 분석을 수행할 수 있게끔 만드는 여정과 관련


# 3.1. 데이터 수집
- 가장 업스트림에 있는 **진입점**
	- 외부 세계의 데이터가 파이프라인에 들어오는 초기 접촉 지점
	- 마치 Docker에서의 Entrypoint
- 진입점의 데이터
	- 그것이 모델링 하는 외부 세계의 전형적인 노이즈, 불규칙성을 모두 포함
	- 제일 원시적
	- e.g. 애플리케이션 로그, 서비스 로그, 클릭 스트림 소스, 라이브 센서, ...
- 데이터 소스는 크게 3가지로 분류됨

## 3.1.1. 애플리케이션 로그 데이터
- 애플리케이션 내의 작업으로 생성된 데이터
- 타임스탬프가 표시되는 이벤트 설명, 애플리케잇녀 소프트웨어 생성 오류, 경고 메세지
- 로그에 포함되거나 불포함 되는 내용이 **개발자**에게 달려 있음
	- 시스템 로그와는 다름
	- 로그 자체가 app 사용에 대한 전체 로그가 아닐 수 있음

### 애플리케이션 로그 데이터 처리시 고려할 점


#### 구조
- app 로그는 단순 **직렬화 텍스트**
	- ASCII 또는 이진 형식으로 사용할 가능성이 높음
- 제약이 거의 없음
- 구조가 매우 다양함

#### 타임 스탬프
- app log text는 `\n`로 구분된 설명이 있는 갭려 이벤트
- 타임스탬프는 이벤트 설명과 달리
	- ISO 표준 형식(`yyyy-mm-ddThh:mm:ss[.mmm]`)이나 유사한 형식으로 표준화 필요

#### 로그 레벨
- 대략적으로 이벤트의 로그 유형 체계화
	- INFO: 순수하게 설명적인 로그
	- WARN: 경고지만 실패는 아님
	- ERROR: app의 프로그래밍 오류

#### 목적
- 로그는 아무렇게나 수집되지 않음
	- 로그 수집 자체도 **비용**이 있기 때문
- 로그를 수집하는 이유?
	- 진단
		- 요청이 얼마나 시간 초과하는가
		- 페이지 로드 속도가 느려지는가
		- 더이상 사용되지 않는 라이브러리를 얼마나 사용하는가
		- 질문에 답변하기 위해 로그를 지능적으로 수집 및 구분 분석 하여 도출
		- 진단 목적으로 로그 데이터 수집시
			- 질문에 대한 답변이 `WARN|ERROR` 로그 일 수 있음
		- 컬렉션의 대부분은 현재 제기하는 **특정 의문**과 관련이 없음
	- 감사
		- 누가 그 요청을 했는가?
		- 몇 번 요청했는가?
		- 시스템은 어떻게 응답했는가?
		- 패턴이 다른가
		- app 내의 이벤트 발생을 기록
		- 대부분의 `INFO`로그가 이 작업에 유용
		- 주로 어플리케이션 세션의 대규모 집계에 활용

## 3.1.2. API 응답
- 하나의 app이 모든 것을 할 수 없기 때문에
	- 특정 기능을 app에 맡김
	- API를 활용
- API는
	- 두 프로그램 사이의 매개체
	- 특정 형식의 **요청**과 **응답**이 필요
	- 목적에 맞는 데이터는 [[반구조화된 데이터]]
- app 로그 외에도 **API Endpoint**에서 가져온 데이터 저장 가능
- 단, 다음 사항에 유의 해야함

### API 응답 사용시 유의점
#### 구조
- 로그처럼 직렬화는 가능하나, **구조화**또는 **반구조화 형식**으로 압축이 풀림
- JSON
	- 우연하지만, 중요한 방식으로 구조에 제약을 받음
	- key-value 혹은 값의 목록
	- 텍스트 스트림일 수도 있는 로그 데이터와 다름
- HTTP
	- HTTP/1.1 와 같은 응답 사양은
	- HTTP 요청 또는 본문에도 JSON|XML 포함 가능

#### 응답 코드
- HTTP 상태 코드
- 다른 코드 표준
	- e.g. HTTP 또는 기타 전송 프로토콜을 사용할 수 있는 `SOAP API`
- 각 코드에는 의미가 있음
	- HTTP 500 응답 속도, 서버 중단 여부를 나타내는 지표
- API 응답 데이터를 저장하는 경우, 이에 대한 고려 필요

#### 목적
- 사용 사례는 API 응답 개체의 어떤 정보가 의미 있는지에 영향을 줄 수 있음
- 특정 상황에서 전송된 정보는 유용하지 않을 수 있음

## 3.1.3. 센서 데이터
- 사물 인터넷 장치, 연구 장비와 같은 센서에서 얻음
- app으로 바로 활용하지는 않음
- 추가로 응용하지 않고 단순히 수집용으로 데이터 전송

### 유의점

#### 노이즈
- 믿을 수 없을 정도로 노이즈가 많음
- 수집 단계에서 초점 x
- 단, 처리량의 중요성은 유의해야 함
- downstream 처리에서
	- 많은 오류값 제거, 평활화 및 기타 변환 수행
- 따라서, 항상 안정적이고 일관된 스트림이 필요

#### 고장 모드
- 센서는 app처럼 똑똑하지 않음
- 센서 실패시 알람을 주지 않을 수 있음
- 수신된 데이터의 양이나, 배치 시간의 시간 [[delta]]와 같은 항목을 영리하게 확인해야 함

#### 목적
- 많은 downstream 작업에 사용
- 오늘날, ML 시스템으로 처리
	- 데이터의 양이 중요할 수 있음
	- 처리량이 중요
- 센서 데이터로 추론 기반 작업시 주의 해야함
	- e.g. 문 앞에서 움직임 감지시 알람 -> 작업의 대기시간이 중요

## 3.2. 데이터 정제
- date cleansing
- 사용 가능한 데이터셋에서 부정확하거나, 대표적이지 않은 데이터 제거
- 데이터 처리 및 데이터 프로덕트 개발 상태에 따라 다양한 종류 존재

### 오류값 제거
- 이상값 제거
	- 표준점수(z점수)와 같은 통계적 기술
	- [[Isolation forest]]와 같은 알고리즘 적용
- 데이터 셋이 큰 경우, 문제 해결 절차에 걸리는 **시간 복잡도**에 유의해야 함

### 데이터셋 특징 평가
- 수집한 데이터의 모든 내용이 다운스트림과 연관 없을 수 있음
	- 그런 섹션은 제거할 것
- 불필요한 데이터 필드 수집은
	- 스토리지 비용 발생
	- 히스토리 추적시 어려움
	- 도메인 지식의 불필요한 확장
	- 분석 복잡도 증가
	- 데이터 품질 저하

### 정규화
- 일부 데이터 포인트는 독립적으로 검사 가능
- 특정 데이터 포인트는 다른 데이터와 비교시 의미 있음
	- 이 경우 정제 및 변환 단계에서 데이터를 정규화 하는것이 도움이 됨
- 정규화에서 자주 사용되는 선택지
	- L1(Manhattan) 정규화
	- L2(Unit) 정규화
	- 평균차분(demeaning) 및 단위 분산
- 최상의 선택이 무엇인지는 데이터 사용 사례에 따라 달라짐

### 데이터 재구성
- 수집한 데이터의 특정 필드 누락
	- cause. 오류 발생이 쉬운 API, 오프라인으로 전환되는 센서
- 일반적으로 누락은 이슈가 없으나, 경우에 따라 모든 필드에 값 지정 필요
	- [[Interpolation|종종 보간법]]
	- [[Extrapolation|외삽법]]
	- 서로 비슷한 데이터의 범주화/분류 등의 기법 사용
		- 기본 수준 범주 레이블 지정 및 자동 식별
			- https://digital.lib.washington.edu/researchworks/handle/1773/43082
- 약간의 노이즈가 포함되겠지만, 오류값 대체 가능

### 시간대 변환
- 표준 시간대 변환, 일종의 정규화로 간주 가능
	- 하지만 시간대 변환 자체가 중요하기 때문에 별도 토픽으로 구성
- 대부분 UTC라는 하나의 기준으로 정리
	- UTC는 표준 시간이지, 시간대는 아님
	- 그리니치 표준시(GMT)를 사용하는 국가는 UTC를 인정하나, 사용하지는 않음
- 시간대 변환 없이 시간대 정보만 수집한다면,
	- 2개의 국제적인 사건 발생시 알기 어려움
- 소프트웨어 버그는 시간대 혼동(e.g. Y2K)으로 추적될 수 있으므로
	- 시간대를 주의 깊게 살펴 UTC로 변환/지정되는지 확인 필요

### 유형 변환
- 대부분의 정형화된 데이터는 유형이 지정됨 => 특정 형식을 따라야 함
	- 하지만 컴퓨팅에서 app이 작동하려면, 형식 변화에 **유동성**을 부여하는 경우가 많음
		- e.g. 부동소수점 => 정수, 문자 => 문자열
- downstream에 특정 유형의 데이터 필요한 경우
	- **정제 프로세스**의 일부로, 한 데이터 유형에서, 다른 데이터 유형으로 값을 **자동**또는 **암시적**으로 변환하는 형식 고려 필요
- 유형 변환은 다른 형식의 데이터 결합하는 경우에도 필수적

## 3.3. 배치 처리 vs 실시간 처리
- 배치 처리
	- 일정 기간 동안 데이터 수집
	- 다량의 데이터를 별개의 패킷으로 '배치'
	- Apache Hadoop
		- 분산 저장 및 대용량 데이터 처리
	- Google BigQuery, Snowflake, Microsoft edge, Amazon redshift
- 실시간 처리
	- 프로세스는 길지만 데이터를 즉시 처리
	- **Apache Kafka**, Amazon Kinesis
	- **Spark**, Flink, Storm, Samza, Flume
	- Databricks, Cloudera

## 3.4. 실시간 처리를 위한 데이터 품질
- 배치 처리와 실시간 처리의 주요 차이점
	- 배치당 처리되는 데이터의 양, 처리 속도
- 배치 처리
	- 지연이 발생하더라도 최대한 많은 양의 데이터를 수집
	- 데이터 품질이 상대적으로 높음
		- 파이프라인에서 주어진 단계에서 데이터의 상태
- 실시간 처리
	- 가능한 한 빨리 데이터를 수집
	- 손실 발생 가능
	- 데이터 품질이 실시간으로 스트리밍 시 오류에 따라 상대적으로 중요함
- 실시간 처리에서 사용되는 데이터 품질 문제를 해결하는 방법?
	- 기존에는 **테스트**를 통해 데이터 품질을 관리
	- 데이터에 대한 가정을 기반으로 작성하나, 모든 결과 설명 불가능
- **테스트는 확장하기 어려웠음**
	- 데이터 품질 문제의 약 20%만 해결 가능했었음
	- [[알려진 미지]]가 존재함
- 아파치 키네시스와 카프카를 활용하여 실시간 처리 시스템의 데이터 품질 관리하기

### [[Amazon Kinesis]]

### [[Apache Kafka]]

스트리밍 시스템의 높은 대기 시간을 고려할 때
- 스트리밍 입력을 다운스트림 시스템으로 직접 **스트리밍**가능
- 단, 이 유형의 분석 데이터는 더 많은 오류를 발생 시킴
- 실시간 또는 거의 실시간으로 이를 이해하는 것이 어려움
	- 분석 사용 사례에 종종 **배치 처리**를 선택하는 이유

[[Apache Kafka|아파치 카프카]]나 [[Amazon Kinesis|아마존 키네시스]] 중에 선택하는 이유는, 조직 요구사항에 따라 달라짐
- SaaS 선호시 키네시스
- 대규모, 구체적인 요구사항시 카프카

데이터 품질 관리를 위해 첫번째 단계는 데이터 정규화임