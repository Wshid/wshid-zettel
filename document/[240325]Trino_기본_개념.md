---
tags:
  - trino
---

# Trino 기본 개념 및 이해하기
- https://blue-it-society.tistory.com/6

## Trino란
- 하나 이상의 heterogeneous data source에 쿼리하도록 설계된 엔진
- RDB등을 대체하는 엔진이 아님

## Trino 특징 및 쿼리 엔진
- hive, spark 등의 느린 쿼리 속도 경험시 trino를 고려함
- 분산 SQL 쿼리 엔진을 통해 빠른 성능을 지원

## 세부 연산 과정
- 분산 SQL 쿼리 엔진
  - 서버 클러스터에 모든 처리를 분산
- 하나의 Worker가 Coordinator에게 데이터를 제공하기 위해
  - 여러 Worker들이 데이터 소스에서 검색 / 협업하여 데이터를 처리

### Connector
- Coordinator, worker와 통신하여 data source에서 데이터를 읽어 오는 역할
- 특정 data source와 관련된 세부 정보 처리
- 역할
  - Table/View/Schema Metadat를 가져옴
  - Trino가 R/W를 parallelize 할 수 있도록
    - **데이터 분할의 논리 단위 생성**
  - Source 데이터를 쿼리 엔진에서 예상하는
    - In-memory(Memory-to-Memory data transfer)으로 변환하는 Data Source 및 Sink

### Coordinator의 로직
- SQL문이 **Coordinator**에게 제출되어 구문 분석 진행
- 쿼리 계획 생성(실행 계획)
- 쿼리 계획 
  - 데이터를 처리하고 SQL문에 따라 결과를 반환하는데 필요한 Stage
  - ![image](https://github.com/Wshid/daily-poc/assets/10006290/cde2a4b6-6381-4a34-bf49-3073215d26e3)
- Coordinator는 전체 쿼리 속도를 높히기 위해
  - 병렬로 Worker가 클러스터에서 처리할 수 있도록 **실행 계획**을 나눔
  - **Stage의 수는 쿼리 복잡성에 따라 다름**
  - ![image](https://github.com/Wshid/daily-poc/assets/10006290/f57b53d4-a31d-4dd3-90ea-29b1babfc78f)

### 분산 쿼리 계획
- Trino에서 쿼리가 실행되는 Stage와 방법을 정의
- Coordinator가
  - `Worker` 전체의 Task를 추가로 계획하고
  - Reserved 하는데 사용
- Stage는 하나 이상의 Task로 구성됨
  - Task는 데이터의 일부를 처리
  - ![image](https://github.com/Wshid/daily-poc/assets/10006290/82d8f739-547c-441f-a835-8854aa8a86bf)

### Split
- Task가 작업을 처리하는 단위를 `Split`이라고 함
- **병렬 처리 및 Task 할당의 단위**
- 서로 다른 Worker에서 **병렬**로 발생
- ![image](https://github.com/Wshid/daily-poc/assets/10006290/720c5998-ab15-40a6-947d-ea6513b53e2c)

### 요약
- 각 Task는 Worker에 할당 될때,
  - **하나 이상의 드라이버**를 사용
- 모든 Driver가 완료되고, 다음 Split으로 전달 시,
  - Driver, Task가 파기됨
- Operator는 **입력 데이터**를 처리하여
  - Downstream Operator에 대한 출력 데이터 생성
- Operator: Table Scan, Filter, Join, Aggregation
- 연속적 Operator는 Operator Pipeline을 형성
  - e.g. 데이터 스캔 이후, 필터링, 데이터에 대한 부분 집계를 수행하는 파이프라인
- ![image](https://github.com/Wshid/daily-poc/assets/10006290/3efc81ce-fd00-4cde-87de-bfe4db3044f5)

### 연산 과정 정리
- [Coordinator] Connector의 Metadata를 사용하여 Split 목록 생성
- [Cooridnator] Split 목록을 사용하여 데이터를 수집하기 위해
  - `Worker`에 대한 Task 예약 시작
- [Coordinator] 쿼리 실행중, Processing에 사용할 수 있는 Worker에서
  - running 중인 `Task`와 `Split`의 위치 추적
- [Coordinator] Task 처리를 완료하고, Downstream 처리를 위해 더 많은 Split을 생성하는 상태
  - Split이 남아 있지 않을 때까지 Stage를 지속 예약
- [Coordinator] 모든 Split이 처리되면 데이터를 사용할 수 있게 되고,
  - Client에게 결과를 반환함

## Trino는 DB인가?
- 다양한 시스템에 질의 할 수 있는 Query Engine
- DB는 아님
- 스토리지가 있는 DB가 아님
  - 데이처가 있는 위치에 데이터를 쿼리
- Trino는 Computing 계층
  - Data Source는 Storage 계층을 나타냄
- RDBMS, 기타 데이터 저장 시스템을 모두 지원하므로
  - Trino를 사용하여 데이터 이동이 가능
- SQL을 사용하여
  - 데이터를 쿼리하고 변환한 데이터를
  - 동일한 위치가 다른 데이터 위치에 사용할 수 있음
  - e.g. object storage system -> RDBMS 복제 가능

## Trino와 Hive
- Trino는 Hive의 느린 쿼리 환경을 개선하기 위해 고안됨
- **Trino의 HiveConnector는 Hive Runtime 코드를 사용하지 X**

### Hive Architecture
- ![image](https://github.com/Wshid/daily-poc/assets/10006290/2962b33a-979d-400d-9036-0a8b733df38f)
- 4가지 구성 요소: Runtime 영역
- [Hiveserver2]client가 제출한 HQL 수령 및 Driver에게 전달
- [Hiveserver2] **권한**, **접근성** 검증 체크
- [Driver] 여러 질의를 받아 Compiler에게 Query Plan 요청을 보내고 받음
- [Compiler] Metastore와 통신하며 쿼리에 필요한 메타정보를 주고 받음
- [Compiler] metadata를 Metastore로부터 받아 `Execution plan`을 생성, 이를 Driver에게 전달
- [Execution Engine] (e.g. MR, Tez, Spark) Dirver에게 Execution plan을 받아 hadoop 모듈과 통신
  - MR Job 수행

### HiveConnector Architecture
- ![image](https://github.com/Wshid/daily-poc/assets/10006290/9e11f372-3a40-4d1e-a964-9f6216f34889)
- **Trino는 Hive의 Runtime 영역을 대체**
- Hive Metastore(Table Schema)만을 사용
  - 유일하게 Trino가 사용하는 Hive Process Component
- Connector
  - **Worker**와 **Data source**(file storage) 사이에 위치
  - Data source에서 데이터를 읽을 수 있도록 Cooridnator, worker와 통신
  - 데이터 소스를 연결해주는 역할
- 실제 Trino 사용시 **Hive Metastore**만 따로 설치하여 사용
  - Storage는 S3, Table Schema는 Hive metastore를 사용하는 경우가 많음
